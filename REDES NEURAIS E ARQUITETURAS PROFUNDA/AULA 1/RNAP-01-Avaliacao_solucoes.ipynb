{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo I - Deep Learning e redes do tipo Perceptron</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação (com soluções)</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questão 1)\n",
    "\n",
    "O que diferencia métodos de aprendizado profundo (*deep learning*) de métodos de aprendizado de máquina considerados rasos (*shallow*)?\n",
    "\n",
    "<font color='red'>(a) Os métodos rasos comumente aprendem um mapeamento direto entre dados de entrada (atributos) e saída (alvo), enquanto os profundos aprendem uma sequência de mapeamentos (ou funções) para múltiplos espaços antes de mapear para o espaço de saída alvo<br></font>\n",
    "(b) Os métodos rasos podem ser considerados aprendizado de máquina e permitem tarefas distintas como classificação, regressão, agrupamento, entre outros, enquanto os chamados profundos permitem modelar tarefas de classificação<br>\n",
    "(c) Os métodos rasos são baseados em métodos estatísticos e árvores de decisão, enquanto os de aprendizado profundo são unicamente baseados em redes neurais<br>\n",
    "(d) Os métodos rasos trabalham apenas com dados estruturados, enquanto que os profundos funcionam com dados estruturados e não estruturados.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questão 2)\n",
    "\n",
    "Seja $\\mathbf{z}$ um vetor de entrada e $\\mathbf{s}$ um vetor de saída de uma camada de rede neural baseada em Perceptron. Essa camada pode ser formulada como:\n",
    "\n",
    "$f(\\mathbf{z}) = a(W\\mathbf{z}+\\mathbf{b}) = \\mathbf{s}$,\n",
    "sendo que $a()$ é a função de ativação. \n",
    "\n",
    "Sabendo que a entrada tem $40$ dimensões e a saída tem $k$ dimensões, Qual o tamanho da matriz $W$ e do vetor $b$ e quantos parâmetros essa camada possui para serem aprendidos durante o treinamento?\n",
    "\n",
    "\n",
    "(a) $W$ possui $40 \\times k$, e $b$ possui $40$ dimensões, totalizando $40k + 40$ parâmetros<br>\n",
    "<font color='red'>(b) $W$ possui $k \\times 40$, e $b$ possui $k$ dimensões, totalizando $41k$ parâmetros<br></font>\n",
    "(c) $W$ possui $k \\times 40$, e $b$ possui 1 dimensão (escalar), totalizando $40k + 1$ parâmetros<br>\n",
    "(d) $W$ possui $k \\times k$, e $b$ possui 40 dimensões, totalizando $2k + 40$ parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questão 3)\n",
    "\n",
    "Qual o impacto do tamanho do batch (lote) no treinamento por meio do Stochastic Gradient Descent (SGD)?\n",
    "\n",
    "(a) O tamanho do batch impacta na quantidade de épocas necessárias para completar o treinamento, se o tamanho do batch for grande, apenas uma época é necessária<br>\n",
    "(b) Quanto menor o tamanho do batch, mais rápido o treinamento, pois assim o SGD se aproxima do Gradient Descent convencional já que utiliza cada exemplo individualmente para adaptar os pesos<br>\n",
    "(c) Quanto menor o tamanho do batch melhor será a acurácia do modelo pois as estimativas do gradiente serão mais precisas considerando cada iteração<br>\n",
    "<font color='red'>(d) Quanto menor o tamanho do batch, mais rápido cada iteração do treinamento, porém mais grosseira é a estimativa do gradiente por iteração<br></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Defina as sementes aleatórias do numpy para 1 e do tensorflow para 2, depois carregue a base de dados boston housing da biblioteca Keras, conforme código abaixo. \n",
    "\n",
    "O objetivo dessa base de dados é obter a regressão do preço das casas com base em 13 características de entrada. Assim, os valores alvo (target) são escalares, tipicamente entre 10 e 50 (representando os preços em milhares de dólares).\n",
    "\n",
    "Utilizando a biblioteca Keras, formule um modelo de rede neural sequencial, do tipo MLP, com 3 camadas ocultas contendo, respectivamente, 32, 16 e 8 neurônios, todas com função de ativação do tipo `relu`.\n",
    "\n",
    "Quantos parâmetros, no total, essa rede possui?\n",
    "\n",
    "(a) 4096<br>\n",
    "<font color='red'>(b) 1121<br></font>\n",
    "(c) 53248<br>\n",
    "(d) 3031<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_target, y_target) = boston_housing.load_data()\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=\"relu\", input_shape=(x_train.shape[1],)),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dense(8, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "Utilizando a base de dados e o modelo de rede neural criado na questão anterior, compile o modelo utilizando uma função de custo `mae` (mean absolute error), o otimizador SGD e a taxa de aprendizado 0.01. \n",
    "\n",
    "Adicione também a métrica `mse` (mean squared error) para permitir avaliá-la adicionalmente.\n",
    "\n",
    "Normalize os dados (x) por meio da normalização z-score (calcule média e desvio no conjunto de treinamento apenas).\n",
    "\n",
    "Utilize os dados normalizados para treinar a rede neural por 15 épocas, com batch-size 4. \n",
    "\n",
    "Avalie o modelo treinado nos dados de teste, e reporte as posições 0 e 1 do score resultante, respectivamente relativas ao MAE e MSE calculados. Escolha a opção para a qual o intervalo se enquadre nos valores computados.\n",
    "\n",
    "(a) MAE = (50,53), MSE = (18,22) <br>\n",
    "(b) MAE = (6,12), MSE = (35,50) <br>\n",
    "(c) MAE = (4,8), MSE = (60,80) <br>\n",
    "<font color='red'>(d) MAE = (1,5), MSE = (15,25)<br></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 15.0842 - mse: 344.3475 - val_loss: 4.7393 - val_mse: 36.6931\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 3.9585 - mse: 32.3051 - val_loss: 5.3942 - val_mse: 46.1902\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 3.2637 - mse: 22.2484 - val_loss: 3.4779 - val_mse: 22.1614\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.9845 - mse: 19.6825 - val_loss: 3.0816 - val_mse: 20.8855\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.8883 - mse: 18.3737 - val_loss: 3.4235 - val_mse: 27.4430\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.8413 - mse: 18.5074 - val_loss: 4.7524 - val_mse: 38.7638\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.5271 - mse: 14.4180 - val_loss: 2.7270 - val_mse: 17.5546\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.7714 - mse: 15.9877 - val_loss: 2.7736 - val_mse: 17.0956\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.6913 - mse: 15.5304 - val_loss: 3.1288 - val_mse: 22.5440\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.6917 - mse: 16.3090 - val_loss: 2.6373 - val_mse: 17.3020\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.5552 - mse: 14.5274 - val_loss: 4.8624 - val_mse: 39.7955\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.4907 - mse: 15.2598 - val_loss: 3.7555 - val_mse: 24.6467\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.5755 - mse: 14.6809 - val_loss: 2.8443 - val_mse: 20.9270\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.5284 - mse: 14.6518 - val_loss: 3.1299 - val_mse: 20.5842\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 2.6219 - mse: 15.6783 - val_loss: 2.7476 - val_mse: 18.6527\n"
     ]
    }
   ],
   "source": [
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "\n",
    "x_target -= mean\n",
    "x_target /= std\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(0.01), loss='mae', metrics=['mse'])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=4,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=(x_target, y_target),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.7\n",
      "MSE: 18.7\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_target, y_target, verbose=0)\n",
    "print(\"MAE: %.1f\" % (score[0]))\n",
    "print(\"MSE: %.1f\" % (score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
