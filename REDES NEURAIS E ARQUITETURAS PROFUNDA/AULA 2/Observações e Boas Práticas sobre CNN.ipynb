{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observações e Boas Práticas sobre CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/2510/1*vkQ0hXDaQv57sALXAJquxA.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Componentes da camada convolucional**<br>\n",
    "- **Motivação**: Uma limitação das redes densas é que caracteristicas espaço-temporais (vizinhança) são mais difíceis de aprender devido ao grande número de possibilidades, assim as camadas convolucionais permitem que características sejam aprendidas por meio de uma estrutura mais larrga.\n",
    "- **Filters**: É a matriz de pesos (equivalente aos neurônios) que armazena os pesos de ajuste (aka. parâmetros).\n",
    "- **Kernel**: É uma  matriz menor que a imagem de entrada que move por sub-regiões da imagem para extrair padrões  aplicando a técnica de convolução.\n",
    "- **Activation Maps** (ou Feature Maps): É o resultado dos pesos dos filtros com o bias após a aplicação da função de ativação, também é conhecido por <i>feature maps</i> onde alguma característica foi encontrada na imagem. Um <i>rectified feature map</i> é basicamente um <i>feature map</i> criado usando ReLU.\n",
    "- **Local Receptive Fields**: Em termos intuitivos podemos entender como a informação que um único neurônio consegue ter acesso. Esse campo local em uma rede convolucional é determinada pelo tamanho do kernel. A principal vantagem é que os neurônios se tornam capazes de reconhecer padrões visuais de pequenas regiões (detalhes) das imagens como bordas, olhos, etc.\n",
    "\n",
    "**Componentes de subamostragem**<br>\n",
    "- **Motivação**: Um problema com feature maps é que são sensíveis a localização das features de entrada. Uma abordagem para resolver esta sensibilidade é realizar uma subamostragem nas feature maps. Isso torna a feature subamostrada mais robusta a mudanças de posição da feature da image. Este problema é conhecido com *local translation invariance*.\n",
    "- **Global Pooling**: *Resume* a camada anterior considerando toda a camada anterior usando algum operador (max ou avg)\n",
    "- **Local Pooling**: *Resume* a camada anterior considerando somente uma região da camada anterior usando algum operador (max ou avg)\n",
    "\n",
    "**Hiper-Parâmetros**\n",
    "- **Motivação**: Controlar a granularidade de detalhes que devem ser considerados.\n",
    "- **Kernel Size**: Tamanho da região do filtro\n",
    "- **Stride**: Passo que será dado em cada direção do kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.ctfassets.net/be04ylp8y0qc/5YOizOUulJQWDtCq5iBxmD/d25614b5a9fd4f8b5f280ed200a82499/dog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Image Size**: a qualidade da imagem fornece mais informação porém requer uma rede maior e um poder computacional maior\n",
    "- **Number of Images**: quanto maior o número de imagens maior a acurácia, mas garanta que os dados de treino representem a população real\n",
    "- **Aspect Ratio**: garanta que as imagens tenham a mesma proporção nas dimensões, comumente é esperado entradas quadradas.\n",
    "- **Image Normalization**: isso torna a convergência mais rápida; uma forma é subtrair média e dividir pelo desvio padrão.\n",
    "- **Number of Channels**: quanto maior o número de canais mais detalhes podem ser aprendidos, o que pode requerer redes maiores, portanto é importante estar alinhado com o objetivo do problema. Em alguns casos pode ser interessante reduzir de RGB para escala cinza para tornar mais eficiente o treinamento.\n",
    "- **Data Augmentation**: é comum para criar variações e aumentar a capacidade de generalização da rede; alguns exemplos são rotação e escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/publication/319413978/figure/fig2/AS:533727585333249@1504261980375/Data-augmentation-using-semantic-preserving-transformation-for-SBIR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiper-parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Kernel Size**: O ideal é manter o *kernel size* pequeno (algo como 3x3 ou 5x5), pois contribui na redução do tempo de treinamento e a maioria das caracteristicas de uma imagem são geralmente locais e quanto mais granular mais [detalhes podem ser aprendidos](https://medium.com/analytics-vidhya/how-to-choose-the-size-of-the-convolution-filter-or-kernel-size-for-cnn-86a55a1e2d15). Note que é mais comum utilizarmos *kernel size* com [dimensões simétricas e com valores impares](https://datascience.stackexchange.com/questions/23183/why-convolutions-always-use-odd-numbers-as-filter-size) a razão disso é que o valor de saída representa uma combinação simétrica entre todos valores ao seu redor, o que evita distorções na captura de característica (similar ao zero-padding).\n",
    "- **Stride**: Uma recomendação comum manter o strides pequenos, e para strides maiores substituir por Pooling. A razão disso está no tempo de treinamento, pois camadas convolucionais demoram mais para treinar do que camadas de pooling. Entretanto há artigos demonstrando que é possivel obter resultados similares ou melhores [utilizando somente camadas de convolução](https://arxiv.org/pdf/1412.6806.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/YDusp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duas arquiteturas com o mesmo número de parâmetros podem produzir resultados muito diferentes\n",
    "- É comum observamos camadas de pooling intercaladas com camadas convolucionais para reduzir o tempo de treinamento\n",
    "- Redes rasas são boas para memorização mas não tão boas para generalização.\n",
    "- A vantagem de múltiplas camadas é que permite aprender features em diferentes níveis de abstração; aprendem com as camadas intermediárias\n",
    "- Se uma rede for muito profunda e muito larga é possível que cada camada acabe memorizando a saída e portanto não generalizando o problema\n",
    "- Quanto mais larga uma rede é, mais tempo longo tende o periodo de treinamento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requerem um alto poder computacional, os modelos geralmente são treinados em máquinas de alto custo usando GPUs\n",
    "- Podem falhar na previsão quando as caracteristicas não estão na ordem, rotação ou posição que foram treinadas originalmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Best Practices for Preparing and Augmenting Image Data for CNNs](https://machinelearningmastery.com/best-practices-for-preparing-and-augmenting-image-data-for-convolutional-neural-networks/)\n",
    "2. [Why is a convolution neural network harder to train on color images compared to grayscale images?](https://www.quora.com/Why-is-a-convolution-neural-network-harder-to-train-on-color-images-compared-to-grayscale-images)\n",
    "3. [A Guide for Building Convolutional Neural Networks](https://towardsdatascience.com/a-guide-for-building-convolutional-neural-networks-e4eefd17f4fd)\n",
    "4. [What is the motivation for pooling in convolutional neural networks (CNN)?](https://www.quora.com/What-is-the-motivation-for-pooling-in-convolutional-neural-networks-CNN)\n",
    "5. [Convolutional Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)\n",
    "6. [Why are neural networks becoming deeper, but not wider?](https://stats.stackexchange.com/questions/222883/why-are-neural-networks-becoming-deeper-but-not-wider)\n",
    "7. [Deciding optimal kernel size for CNN](https://towardsdatascience.com/deciding-optimal-filter-size-for-cnns-d6f7b56f9363)\n",
    "8. [Pooling vs. stride for downsampling](https://stats.stackexchange.com/questions/387482/pooling-vs-stride-for-downsampling)\n",
    "9. [Understanding the receptive field of deep convolutional networks](https://theaisummer.com/receptive-field/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [MNIST demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html)\n",
    "2. [ONNX Model Zoo](https://github.com/onnx/models)\n",
    "3. [Tools to Design or Visualize Architecture of Neural Network](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
