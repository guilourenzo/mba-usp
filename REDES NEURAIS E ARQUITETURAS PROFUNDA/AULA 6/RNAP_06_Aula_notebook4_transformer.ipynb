{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNAP-06-Aula-notebook4_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvaEK6Bn-wwG"
      },
      "source": [
        "## MBA em Ciência de Dados\n",
        "# Redes Neurais e Arquiteturas Profundas\n",
        "\n",
        "### <span style=\"color:darkred\">Módulo 6 - Redes neurais para dados sequenciais</span>\n",
        "\n",
        "#### <span style=\"color:darkred\">**Parte 4: Transformer Network**</span>\n",
        "\n",
        "Moacir Antonelli Ponti\n",
        "\n",
        "CeMEAI - ICMC/USP São Carlos\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvtQgvYq_z7v"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5iOeI4lqbm",
        "outputId": "3a93f5a0-ed4e-493b-cd69-1d674d43b24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-18 00:09:58--  http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 181356545 (173M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fglove%2Fglove_s50.zip’\n",
            "\n",
            "download.php?file=e 100%[===================>] 172.96M  9.32MB/s    in 27s     \n",
            "\n",
            "2020-10-18 00:10:26 (6.37 MB/s) - ‘download.php?file=embeddings%2Fglove%2Fglove_s50.zip’ saved [181356545/181356545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xsQ97N_pmUn"
      },
      "source": [
        "!mv download.php?file=embeddings%2Fglove%2Fglove_s50.zip glove_s50.zip\n",
        "!unzip -q glove_s50.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgO7dF4s9D7X",
        "outputId": "5643fac9-9c54-44bb-ef1f-55d6d08e0d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove_s50.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Encontrados %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Encontrados 929594 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBPgAvQHrk-f",
        "outputId": "d1d02d2b-6b15-4efa-e90b-046d91466658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(embeddings_index['aprovação'])\n",
        "print(len(embeddings_index['aprovação']))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 6.984870e-01  1.938170e-01  1.839920e-01 -2.590166e+00 -3.155430e-01\n",
            " -1.469410e-01  1.290320e-01  3.814410e-01 -4.846610e-01  3.721310e-01\n",
            "  6.471990e-01 -1.248160e+00 -3.151210e-01  3.676890e-01 -7.965720e-01\n",
            "  2.589710e-01 -1.260200e-02 -6.782460e-01 -4.735670e-01  3.739230e-01\n",
            "  1.437597e+00  2.001800e-02  9.999200e-02 -1.829620e-01  2.779400e-01\n",
            "  1.222500e-01 -2.345070e-01 -7.791430e-01  6.422940e-01  3.167230e-01\n",
            " -3.914640e-01  3.333300e-01  2.291640e-01 -9.465310e-01 -2.157560e-01\n",
            " -3.246800e-02 -3.029230e-01  9.146800e-02 -1.788646e+00 -2.995630e-01\n",
            " -3.183580e-01 -7.586490e-01  2.524000e-03 -6.656960e-01  7.843900e-01\n",
            "  1.341660e-01  6.273990e-01  3.014050e-01 -4.354190e-01  1.121057e+00]\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNykW-NnniWS",
        "outputId": "50db4cc6-1019-4e9e-ae90-0d45ae0cbe14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df = pd.read_csv(\"rumor-election-brazil-2018.csv\", delimiter=';')\n",
        "texto = df['texto']\n",
        "rotulos = (df['rotulo']=='VERDADE').astype(int)\n",
        "\n",
        "class_names = [\"FALSO\", \"VERDADEIRO\"]\n",
        "\n",
        "print(texto[:10])\n",
        "print(rotulos[:10])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Salário Mínimo: R$ 950,00. Bolsa Presidiário: ...\n",
            "1    Empresa contratada pelo TSE para apuração dos ...\n",
            "2    O Aloizio Mercadante, ministro da Educação, mo...\n",
            "3    Há um complô espalhando fake news descaradas e...\n",
            "4    Somente em 2017, mais de 800 milhões de tonela...\n",
            "5    Nunca vi o Lula pronunciar essa palavra fascis...\n",
            "6    O Mourão, por exemplo, foi ele próprio tortura...\n",
            "7    O PSB, todos os seus governadores e o seu pres...\n",
            "8    Bolsonaro Nunca aprovou um projeto de seguranç...\n",
            "9    Ele Lula não pode aparecer mais que 25% no hor...\n",
            "Name: texto, dtype: object\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    1\n",
            "5    0\n",
            "6    0\n",
            "7    0\n",
            "8    1\n",
            "9    1\n",
            "Name: rotulo, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ11lJuvFr-i",
        "outputId": "31e6bc6f-4d11-42c0-da81-9676d6db18f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "rng = np.random.RandomState(1)\n",
        "rng.shuffle(texto)\n",
        "rng = np.random.RandomState(1)\n",
        "rng.shuffle(rotulos)\n",
        "\n",
        "validation_split = 0.1\n",
        "num_validation = int(validation_split * len(texto))\n",
        "x_train = texto[:-num_validation]\n",
        "x_val = texto[-num_validation:]\n",
        "y_train = rotulos[:-num_validation]\n",
        "y_val = rotulos[-num_validation:]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2-a0lZutC7b"
      },
      "source": [
        "Vocabulário irá considerar até 20 mil palavras, e irá truncar sequências com mais de 32 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-L2MpeWsNx5"
      },
      "source": [
        "vocab_size = 20000 \n",
        "maxlen = 25\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=vocab_size, output_sequence_length=maxlen)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(x_train).batch(16)\n",
        "vectorizer.adapt(text_ds)\n",
        "\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgD5_4jLsCz9",
        "outputId": "90b329a1-bd8f-4534-ad8d-574af1231a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "print(\"Número de tokens: \", num_tokens)\n",
        "embedding_dim = 50\n",
        "convertidas = 0\n",
        "falhas = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "print(embedding_matrix.shape)\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        if (embedding_vector.shape[0] != embedding_dim):\n",
        "          falhas += 1\n",
        "        else:\n",
        "          # Words not found in embedding index will be all-zeros.\n",
        "          # This includes the representation for \"padding\" and \"OOV\"\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "          convertidas += 1\n",
        "    else:\n",
        "        falhas += 1\n",
        "\n",
        "print(\"Palavras convertidas: %d / não convertidas: %d)\" % (convertidas, falhas))\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de tokens:  1944\n",
            "(1944, 50)\n",
            "Palavras convertidas: 1785 / não convertidas: 157)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ3zdvrs8hCJ",
        "outputId": "5e8cf304-5a71-45f0-8bf8-86601354073f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x_train = vectorizer(np.array([[s] for s in x_train])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in x_val])).numpy()\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(414, 25)\n",
            "(46, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFDbWOCiKc7S"
      },
      "source": [
        "---\n",
        "## Implementação de Transformer\n",
        "\n",
        "Apoorv Nandan\n",
        "\n",
        "https://keras.io/examples/nlp/text_classification_with_transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAy-BdnGNtpb"
      },
      "source": [
        "Camada Multi-head Self-attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx6B7fRkr-yY"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQRssUNTNxu7"
      },
      "source": [
        "Bloco Transformer com Atenção + combinação residual + normalização + dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRfn1mboCTMz"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w771u_m2N9Rd"
      },
      "source": [
        "#### Camada de Embedding, contendo word embedding e vetor com posições das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSQgGeRvCVQJ"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim, embedding_matrix):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(\n",
        "            input_dim=maxlen, \n",
        "            output_dim=embed_dim,\n",
        "            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "            trainable=False)\n",
        "        self.pos_emb = layers.Embedding(\n",
        "            input_dim=maxlen, \n",
        "            output_dim=embed_dim)\n",
        "        \n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwTRP3grOFRM"
      },
      "source": [
        "### Montando a rede Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rplrWWEeCXia",
        "outputId": "5d8ec24b-4bff-4274-ac12-0a21c4049ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(num_tokens, vocab_size, embedding_dim, embedding_matrix)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "modelT = keras.Model(inputs=inputs, outputs=outputs)\n",
        "modelT.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_49\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_34 (InputLayer)        [(None, 25)]              0         \n",
            "_________________________________________________________________\n",
            "token_and_position_embedding (None, 25, 50)            194400    \n",
            "_________________________________________________________________\n",
            "transformer_block_18 (Transf (None, 25, 50)            13682     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_17  (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 208,915\n",
            "Trainable params: 111,715\n",
            "Non-trainable params: 97,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYbD6f0eukTT",
        "outputId": "40826211-0a01-436c-cb80-2f2d4dc1f5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        }
      },
      "source": [
        "modelT.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = modelT.fit(\n",
        "    x_train, y_train, batch_size=32, epochs=20, validation_data=(x_val, y_val)\n",
        ")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "13/13 [==============================] - 0s 37ms/step - loss: 0.7746 - accuracy: 0.4928 - val_loss: 0.6834 - val_accuracy: 0.5435\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.6857 - accuracy: 0.5604 - val_loss: 0.6806 - val_accuracy: 0.6522\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5483 - val_loss: 0.6776 - val_accuracy: 0.6957\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5435 - val_loss: 0.6790 - val_accuracy: 0.5652\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.6730 - accuracy: 0.5821 - val_loss: 0.6776 - val_accuracy: 0.5870\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.6664 - accuracy: 0.6039 - val_loss: 0.6694 - val_accuracy: 0.6087\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.6609 - accuracy: 0.5894 - val_loss: 0.6773 - val_accuracy: 0.5870\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.6549 - accuracy: 0.6063 - val_loss: 0.6692 - val_accuracy: 0.6522\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.6384 - accuracy: 0.6329 - val_loss: 0.6645 - val_accuracy: 0.6304\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 0.6273 - accuracy: 0.6498 - val_loss: 0.6759 - val_accuracy: 0.5870\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.6105 - accuracy: 0.6618 - val_loss: 0.6245 - val_accuracy: 0.6304\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.6160 - accuracy: 0.6618 - val_loss: 0.7500 - val_accuracy: 0.5217\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.6715 - val_loss: 0.6549 - val_accuracy: 0.5870\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.5780 - accuracy: 0.7029 - val_loss: 0.7439 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.5860 - accuracy: 0.6836 - val_loss: 0.6851 - val_accuracy: 0.5652\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.5463 - accuracy: 0.7126 - val_loss: 0.7097 - val_accuracy: 0.5435\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.5396 - accuracy: 0.7271 - val_loss: 0.6532 - val_accuracy: 0.6087\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.5490 - accuracy: 0.7005 - val_loss: 0.6739 - val_accuracy: 0.6087\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.5293 - accuracy: 0.7464 - val_loss: 0.7033 - val_accuracy: 0.5652\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.5084 - accuracy: 0.7729 - val_loss: 0.6939 - val_accuracy: 0.5435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iimkRQpgO5eS",
        "outputId": "6ec7b714-0c5a-4325-d7a8-8b67600aa724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = modelT(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "frase = \"Na pós graduação, as mulheres são maioria\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"Acabou a corrupção no Brasil\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
            "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  VERDADEIRO\n",
            "Acabou a corrupção no Brasil :  FALSO\n",
            "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}