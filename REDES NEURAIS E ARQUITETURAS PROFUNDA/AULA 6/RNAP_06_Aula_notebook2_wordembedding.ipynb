{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNAP-06-Aula-notebook2_wordembedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvaEK6Bn-wwG"
      },
      "source": [
        "## MBA em Ciência de Dados\n",
        "# Redes Neurais e Arquiteturas Profundas\n",
        "\n",
        "### <span style=\"color:darkred\">Módulo 6 - Redes neurais para dados sequenciais</span>\n",
        "\n",
        "#### <span style=\"color:darkred\">**Parte 2: Word Embedding**</span>\n",
        "\n",
        "Moacir Antonelli Ponti\n",
        "\n",
        "CeMEAI - ICMC/USP São Carlos\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvtQgvYq_z7v"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVCHWi9KriW"
      },
      "source": [
        "## Carregando representações pré-treinadas em português \n",
        "\n",
        "Após salvar, vamos montar um dicionário com palavra/vetor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5iOeI4lqbm",
        "outputId": "da8d9c0d-5364-42cd-b816-9d5bd6e54d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-17 22:48:10--  http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 181356545 (173M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fglove%2Fglove_s50.zip’\n",
            "\n",
            ".php?file=embedding   9%[>                   ]  16.33M   884KB/s    eta 3m 36s ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xsQ97N_pmUn",
        "outputId": "f0380e31-9988-4757-d2cf-a343cc053414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "!mv download.php?file=embeddings%2Fglove%2Fglove_s50.zip glove_s50.zip\n",
        "!unzip -q glove_s50.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[glove_s50.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of glove_s50.zip or\n",
            "        glove_s50.zip.zip, and cannot find glove_s50.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgO7dF4s9D7X",
        "outputId": "0f79d0be-3544-4fcd-b1e0-2fdf474d54da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove_s50.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Encontrados %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Encontrados 929594 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBPgAvQHrk-f",
        "outputId": "de4cd802-4270-44e8-aa5a-c322c3b6c14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(embeddings_index['aprovação'])\n",
        "print(len(embeddings_index['aprovação']))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 6.984870e-01  1.938170e-01  1.839920e-01 -2.590166e+00 -3.155430e-01\n",
            " -1.469410e-01  1.290320e-01  3.814410e-01 -4.846610e-01  3.721310e-01\n",
            "  6.471990e-01 -1.248160e+00 -3.151210e-01  3.676890e-01 -7.965720e-01\n",
            "  2.589710e-01 -1.260200e-02 -6.782460e-01 -4.735670e-01  3.739230e-01\n",
            "  1.437597e+00  2.001800e-02  9.999200e-02 -1.829620e-01  2.779400e-01\n",
            "  1.222500e-01 -2.345070e-01 -7.791430e-01  6.422940e-01  3.167230e-01\n",
            " -3.914640e-01  3.333300e-01  2.291640e-01 -9.465310e-01 -2.157560e-01\n",
            " -3.246800e-02 -3.029230e-01  9.146800e-02 -1.788646e+00 -2.995630e-01\n",
            " -3.183580e-01 -7.586490e-01  2.524000e-03 -6.656960e-01  7.843900e-01\n",
            "  1.341660e-01  6.273990e-01  3.014050e-01 -4.354190e-01  1.121057e+00]\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy0O2L2WK6D7"
      },
      "source": [
        "## Base de dados: rumor Brazil 2018\n",
        "\n",
        "Base de dados de texto para classificação em frases \"falsas\" ou \"verdadeiras\" conforme checado por agências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNykW-NnniWS",
        "outputId": "9b3863ff-dda5-4dcb-c471-e52229b6c8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df = pd.read_csv(\"rumor-election-brazil-2018.csv\", delimiter=';')\n",
        "texto = df['texto']\n",
        "rotulos = (df['rotulo']=='VERDADE').astype(int)\n",
        "\n",
        "class_names = [\"FALSO\", \"VERDADEIRO\"]\n",
        "\n",
        "print(texto[:10])\n",
        "print(rotulos[:10])"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Salário Mínimo: R$ 950,00. Bolsa Presidiário: ...\n",
            "1    Empresa contratada pelo TSE para apuração dos ...\n",
            "2    O Aloizio Mercadante, ministro da Educação, mo...\n",
            "3    Há um complô espalhando fake news descaradas e...\n",
            "4    Somente em 2017, mais de 800 milhões de tonela...\n",
            "5    Nunca vi o Lula pronunciar essa palavra fascis...\n",
            "6    O Mourão, por exemplo, foi ele próprio tortura...\n",
            "7    O PSB, todos os seus governadores e o seu pres...\n",
            "8    Bolsonaro Nunca aprovou um projeto de seguranç...\n",
            "9    Ele Lula não pode aparecer mais que 25% no hor...\n",
            "Name: texto, dtype: object\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    1\n",
            "5    0\n",
            "6    0\n",
            "7    0\n",
            "8    1\n",
            "9    1\n",
            "Name: rotulo, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ11lJuvFr-i",
        "outputId": "441617a0-6310-4538-90a2-4d18b7dba71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "rng = np.random.RandomState(1)\n",
        "rng.shuffle(texto)\n",
        "rng = np.random.RandomState(1)\n",
        "rng.shuffle(rotulos)\n",
        "\n",
        "validation_split = 0.1\n",
        "num_validation = int(validation_split * len(texto))\n",
        "x_train = texto[:-num_validation]\n",
        "x_val = texto[-num_validation:]\n",
        "y_train = rotulos[:-num_validation]\n",
        "y_val = rotulos[-num_validation:]"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2-a0lZutC7b"
      },
      "source": [
        "Vocabulário irá considerar até 20 mil palavras, e irá truncar sequências com mais de 32 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-L2MpeWsNx5"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=32)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(x_train).batch(16)\n",
        "vectorizer.adapt(text_ds)\n",
        "\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-EOJZN3LGFx"
      },
      "source": [
        "Podemos ver o resultado do vetorizador, que exibe 1 para palavras fora do vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_DF96isQQI",
        "outputId": "ac69934b-7f35-4758-ab27-32ac58bce0d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "output = vectorizer([[\"um dois one two three\"]])\n",
        "output.numpy()[0, :5]"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 92,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIRN7jpDLLnW"
      },
      "source": [
        "Abaixo, considerando o número de tokens (palavras) da base de dados, vamos tentar gerar seus embedding vectors.\n",
        "\n",
        "Palavras fora do vocabulário não são convertidas. Comumente artigos, números e outros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgD5_4jLsCz9",
        "outputId": "c06b75af-bfbc-442e-e4de-0f06ec952c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "print(\"Número de tokens: \", num_tokens)\n",
        "embedding_dim = 50\n",
        "convertidas = 0\n",
        "falhas = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "print(embedding_matrix.shape)\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        if (embedding_vector.shape[0] != embedding_dim):\n",
        "          falhas += 1\n",
        "        else:\n",
        "          # Words not found in embedding index will be all-zeros.\n",
        "          # This includes the representation for \"padding\" and \"OOV\"\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "          convertidas += 1\n",
        "    else:\n",
        "        falhas += 1\n",
        "\n",
        "print(\"Palavras convertidas: %d / não convertidas: %d)\" % (convertidas, falhas))"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de tokens:  1944\n",
            "(1944, 50)\n",
            "Palavras convertidas: 1785 / não convertidas: 157)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i7ACPhgLhEX"
      },
      "source": [
        "Montando a base de dados para o treinamento, no formato numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ3zdvrs8hCJ",
        "outputId": "042181f3-9eca-4926-ec5a-15fd1766f517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x_train = vectorizer(np.array([[s] for s in x_train])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in x_val])).numpy()\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(414, 32)\n",
            "(46, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB8_ADE9LkHC"
      },
      "source": [
        "## Camada de \"Word Embedding\"\n",
        "\n",
        "Para isso devemos informar o número de palavras, a dimensionalidade e passar a matrix com pesos pré-treinados.\n",
        "\n",
        "Caso não utilizemos os parâmetros `embeddings_initializer`, os pesos serão aleatórios.\n",
        "\n",
        "Também deixamos essa camada não treinável pois não queremos modificar as representações "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKNJE4NpHdu0"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ClTHexL5j5"
      },
      "source": [
        "### Modelo baseado em Convoluções"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx6B7fRkr-yY",
        "outputId": "9e81f640-2993-4392-d1f7-6d20e5dbe60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\")(embedded_sequences)\n",
        "x = layers.Conv1D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "modelConv = keras.Model(int_sequences_input, preds)\n",
        "modelConv.summary()"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_256\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_136 (InputLayer)       [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      multiple                  97200     \n",
            "_________________________________________________________________\n",
            "conv1d_55 (Conv1D)           (None, None, 64)          9664      \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, None, 128)         24704     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_19 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 139,889\n",
            "Trainable params: 42,689\n",
            "Non-trainable params: 97,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYbD6f0eukTT",
        "outputId": "2e6a8df3-feaa-49dd-808d-67c7f55ccbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "seed(1)\n",
        "set_seed(2)\n",
        "\n",
        "modelConv.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"]\n",
        ")\n",
        "modelConv.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.4855 - val_loss: 0.6850 - val_acc: 0.6087\n",
            "Epoch 2/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6586 - acc: 0.5942 - val_loss: 0.6638 - val_acc: 0.5652\n",
            "Epoch 3/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5969 - acc: 0.7150 - val_loss: 0.6698 - val_acc: 0.5435\n",
            "Epoch 4/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5463 - acc: 0.7295 - val_loss: 0.6558 - val_acc: 0.6087\n",
            "Epoch 5/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4820 - acc: 0.7826 - val_loss: 0.6587 - val_acc: 0.6304\n",
            "Epoch 6/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3935 - acc: 0.8285 - val_loss: 0.6707 - val_acc: 0.6087\n",
            "Epoch 7/20\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3365 - acc: 0.8744 - val_loss: 0.6568 - val_acc: 0.6522\n",
            "Epoch 8/20\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.2066 - acc: 0.9541 - val_loss: 0.6742 - val_acc: 0.6739\n",
            "Epoch 9/20\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1520 - acc: 0.9662 - val_loss: 0.7243 - val_acc: 0.6957\n",
            "Epoch 10/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0982 - acc: 0.9855 - val_loss: 0.7235 - val_acc: 0.6304\n",
            "Epoch 11/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0674 - acc: 0.9855 - val_loss: 0.7967 - val_acc: 0.6957\n",
            "Epoch 12/20\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.0442 - acc: 0.9976 - val_loss: 0.8561 - val_acc: 0.6957\n",
            "Epoch 13/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.8416 - val_acc: 0.6304\n",
            "Epoch 14/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.9321 - val_acc: 0.6739\n",
            "Epoch 15/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.9483 - val_acc: 0.6304\n",
            "Epoch 16/20\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.0668 - val_acc: 0.7174\n",
            "Epoch 17/20\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.9622 - val_acc: 0.6739\n",
            "Epoch 18/20\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.6522\n",
            "Epoch 19/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0917 - val_acc: 0.6957\n",
            "Epoch 20/20\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.0906 - val_acc: 0.6522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe858156f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzIdAcnKMDiz"
      },
      "source": [
        "Podemos agora testar frases novas!\n",
        "\n",
        "Para isso vou criar uma camada de entrada que passa por um vetorizador, e depois alimenta o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iimkRQpgO5eS",
        "outputId": "cd231c40-b0fd-4355-bcd1-94efaa1e6470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = modelConv(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "frase = \"Na pós graduação, as mulheres são maioria\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"Acabou a corrupção no Brasil\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
        "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
            "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  VERDADEIRO\n",
            "Acabou a corrupção no Brasil :  VERDADEIRO\n",
            "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utj_ygXrMLh2"
      },
      "source": [
        "### Modelo utilizando GRU\n",
        "\n",
        "Vamos substituir uma camada convolucional por uma GRU (poderia ser uma LSTM também)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLvDalHe6Ol7",
        "outputId": "82c09324-032d-4864-9ddc-af5d0b381cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(64, 2, activation=\"relu\", padding=\"same\")(embedded_sequences)\n",
        "x = layers.GRU(64, input_shape=(1, 1))(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predsGRUout = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "modelGRU = keras.Model(inputs=int_sequences_input, outputs=predsGRUout)\n",
        "modelGRU.summary()"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_268\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_142 (InputLayer)       [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      multiple                  97200     \n",
            "_________________________________________________________________\n",
            "conv1d_59 (Conv1D)           (None, None, 64)          6464      \n",
            "_________________________________________________________________\n",
            "gru_21 (GRU)                 (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 132,849\n",
            "Trainable params: 35,649\n",
            "Non-trainable params: 97,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpqJfZgX6poK",
        "outputId": "0db1fa4b-26e9-4524-e67a-e6618141c98c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        }
      },
      "source": [
        "seed(1)\n",
        "set_seed(2)\n",
        "\n",
        "modelGRU.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"]\n",
        ")\n",
        "modelGRU.fit(x_train, y_train, batch_size=16, epochs=25, validation_data=(x_val, y_val))"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "26/26 [==============================] - 1s 37ms/step - loss: 0.6929 - acc: 0.4952 - val_loss: 0.7073 - val_acc: 0.5435\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6861 - acc: 0.4952 - val_loss: 0.6992 - val_acc: 0.4348\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6832 - acc: 0.5217 - val_loss: 0.7058 - val_acc: 0.5435\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6735 - acc: 0.5217 - val_loss: 0.7049 - val_acc: 0.4348\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.6712 - acc: 0.5266 - val_loss: 0.7069 - val_acc: 0.4783\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 17ms/step - loss: 0.6658 - acc: 0.5386 - val_loss: 0.7039 - val_acc: 0.4565\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6542 - acc: 0.5507 - val_loss: 0.7111 - val_acc: 0.4130\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6479 - acc: 0.5266 - val_loss: 0.6915 - val_acc: 0.5652\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6339 - acc: 0.6087 - val_loss: 0.7564 - val_acc: 0.4565\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6316 - acc: 0.6135 - val_loss: 0.7626 - val_acc: 0.5217\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 0.6269 - acc: 0.5990 - val_loss: 0.6841 - val_acc: 0.4783\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.6006 - acc: 0.6184 - val_loss: 0.7217 - val_acc: 0.4565\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5997 - acc: 0.6304 - val_loss: 0.6884 - val_acc: 0.4565\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6067 - acc: 0.6329 - val_loss: 0.6860 - val_acc: 0.5652\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.5746 - acc: 0.6932 - val_loss: 0.6561 - val_acc: 0.6087\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.5803 - acc: 0.6908 - val_loss: 0.6273 - val_acc: 0.7174\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5368 - acc: 0.7295 - val_loss: 0.6756 - val_acc: 0.5652\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.5376 - acc: 0.7126 - val_loss: 0.5864 - val_acc: 0.7826\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.4958 - acc: 0.7536 - val_loss: 0.6280 - val_acc: 0.5217\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.4749 - acc: 0.7367 - val_loss: 1.1400 - val_acc: 0.6087\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.4582 - acc: 0.7705 - val_loss: 0.7207 - val_acc: 0.6739\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.3740 - acc: 0.8285 - val_loss: 0.8093 - val_acc: 0.6739\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 17ms/step - loss: 0.3053 - acc: 0.8623 - val_loss: 0.7429 - val_acc: 0.7391\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 17ms/step - loss: 0.2548 - acc: 0.8792 - val_loss: 0.7180 - val_acc: 0.7174\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.2397 - acc: 0.9155 - val_loss: 1.0129 - val_acc: 0.6522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe854ce4518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiLfD7Ln643M",
        "outputId": "f84c2e2e-f6ae-4a43-d60c-b90d87f95aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "predsGRU = modelGRU(x)\n",
        "end_to_end_modelGRU = keras.Model(string_input, predsGRU)\n",
        "\n",
        "frase = \"Na pós graduação, as mulheres são maioria\"\n",
        "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
        "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"Acabou a corrupção no Brasil\"\n",
        "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])\n",
        "\n",
        "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
        "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
        "print(frase, ': ', class_names[classe[0]])"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
            "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  FALSO\n",
            "Acabou a corrupção no Brasil :  FALSO\n",
            "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqbvrVfu7HDH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}