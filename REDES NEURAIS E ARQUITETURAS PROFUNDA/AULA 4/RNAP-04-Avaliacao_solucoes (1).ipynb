{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo IV - Estratégias de Treinamento e Transferência de Aprendizado</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação (com soluções)</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "As respostas devem ser dadas no Moodle, use esse notebook apenas para gerar o código necessário para obter as respostas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "\n",
    "### Questão 1)\n",
    "\n",
    "Qual a relação entre o modelo chamado de \"memorizador\" e as redes neurais profundas?\n",
    "\n",
    "(a) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, tornando-as hábeis para generalizar para dados futuros.<br>\n",
    "<font color='red'>(b) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, falhando em predizer corretamente exemplos não vistos.<br></font>\n",
    "(c) Redes neurais com alta capacidade são imunes a convergir para modelos memorizadores, pois obtiveram resultados do estado-da-arte em muitas aplicações.<br>\n",
    "(d) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, e portanto possuem viés forte.<br>\n",
    "\n",
    "**Justificativa:** O modelo ''memória´´ ou memorizador é considerado o caso extremo de overfitting em que o modelo tem custo zero no treinamento, mas falha em obter predição em qualquer exemplo que fujam aos vistos no treinamento. Redes neurais profundas possuem tipicamente grande quantidade de parâmetros, podendo convergir para modelos desse tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 2)\n",
    "\n",
    "O papel do uso conjunto dos métodos BatchNormalization e Regularização é o de:\n",
    "\n",
    "(a) Pré-processamento dos dados antes da realização do treinamento<br>\n",
    "(b) Gerar espaço de parâmetros esparsos, com alguns poucos parâmetros com valor alto e muitos com valores próximo a zero, melhorando a generalização<br>\n",
    "<font color='red'>(c) Minimizar o problema do desaparecimento do gradiente, e ao mesmo tempo evitar que poucas unidades/neurônios se especializem demais<br></font>\n",
    "(d) Obter robustez com relação à possíveis ataques e propiciar modelos menores com acurácia similar a modelos maiores<br>\n",
    "\n",
    "**Justificativa:** Métodos de normalização auxiliam no treinamento suavizando o gradiente (e evitando seu desaparecimento), e de regularização evitam especialização de poucos pesos/neurônios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Questão 3)\n",
    "\n",
    "São práticas viáveis para o uso de aprendizado profundo com pequenas bases de dados:\n",
    "\n",
    " (a) Carregar uma rede neural profunda popular de um pacote de software e treiná-la a partir de pesos aleatórios<br>\n",
    " (b) Carregar uma rede neural profunda pré-treinada em grande base de dados, e utilizar a saída da última camada  da rede, ou seja as predições das classes, como característica para modelos de aprendizado externos que permitem uso com menores bases de dados<br>\n",
    " (c) Carregar uma rede neural profunda popular de um pacote de software e treiná-la a partir de pesos aleatórios utilizando Batch Normalization<br>\n",
    " <font color='red'>(d) Carregar uma rede neural profunda pré-treinada em grande base de dados, inserindo uma nova camada de saída treinando apenas essa camada com a pequena base de dados</font><br>\n",
    " \n",
    " **Justificativa**: dentre as opções, treinar a partir de pesos aleatórios é comumente inviável em bases pequenas, além disso, apesar de possível, o uso da ativação da última camada da rede (predição das classes) não é recomendado pois traz semântica específica do conjunto de dados com o qual foi treinado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Carregue a base de dados Fashion MNIST conforme código abaixo e crie um modelo de CNN com a seguinte arquitetura, capaz de obter classificação nessa base de dados de imagens. Considere que todas as camadas convolucionais tem zeropadding, e ativação relu, exceto quando mencionado contrário.\n",
    "\n",
    "1. Pré-processamento para aumentação contendo:\n",
    "  * RandomZoom(0.1),\n",
    "  * RandomContrast(0.2)\n",
    "1. Convolucional 2D com 64 filtros $3\\times 3$.\n",
    "2. Batch Normalization\n",
    "3. SeparableConv2D com 64 filtros $3\\times 3$.\n",
    "4. MaxPooling2D $3\\times 3$ e strides $2$\n",
    "5. Batch Normalization\n",
    "6. SeparableConv2D com 256 filtros $3\\times 3$.\n",
    "7. MaxPooling2D $3\\times 3$ e strides $2$\n",
    "8. GlobalAveragePooling\n",
    "9. Dropout de 0.2\n",
    "10. Densa com ativação softmax\n",
    "\n",
    "Incialize as sementes do numpy com 1 e tensorflow com 2 e treine o modelo por 7 épocas com batch size 16, otimizador Adam e taxa de aprendizado 0.002.\n",
    "\n",
    "Após o treinamento utilize a função predict para classificar imagens da posicao 10 a 14 no conjunto de testes ([10:15]). Quais as classes resultantes e quantas dessas estavam erradas?\n",
    "\n",
    "(a) 2, 5, 5, 3, 3, sendo 2 erradas<br>\n",
    "(b) 4, 5, 5, 3, 4, sendo 2 erradas<br>\n",
    "<font color='red'>(c) 4, 5, 5, 3, 4 sendo 1 errada<br></font>\n",
    "(d) 4, 5, 5, 3, 4, nenhuma errada<br>\n",
    "\n",
    " **Justificativa**: Ver código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rif40G6wST-s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9VFB_hc7PC0e"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def my_cnn(input_shape, num_classes, dropout_rate=0.0):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.SeparableConv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.SeparableConv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "YpiKc7c6P39d",
    "outputId": "dcd70326-21e4-40d9-8803-80e0abecdba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5496 - accuracy: 0.7965\n",
      "Epoch 2/7\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.3869 - accuracy: 0.8577\n",
      "Epoch 3/7\n",
      "3750/3750 [==============================] - 97s 26ms/step - loss: 0.3473 - accuracy: 0.8738\n",
      "Epoch 4/7\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.3273 - accuracy: 0.8801\n",
      "Epoch 5/7\n",
      "3750/3750 [==============================] - 112s 30ms/step - loss: 0.3149 - accuracy: 0.8845\n",
      "Epoch 6/7\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.3037 - accuracy: 0.8881\n",
      "Epoch 7/7\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.2950 - accuracy: 0.8928\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_seed(2)\n",
    "epochs = 7\n",
    "batch_size=16\n",
    "model1 = my_cnn((28,28,1), 10, 0.2)\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.002),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist1 = model1.fit(train_images, train_labels, batch_size=batch_size,\n",
    "                    epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2414 - accuracy: 0.9110\n",
      "[0.24139392375946045, 0.9110333323478699]\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(train_images, train_labels)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "r6cPrk_iUnPu",
    "outputId": "33771c3c-9ad9-4df6-fc31-479c752d260b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 5 3 4]\n",
      "[4 5 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(test_images[10:15])\n",
    "print(np.argmax(y_pred,1))\n",
    "print(np.argmax(test_labels[10:15],1))\n",
    "\n",
    "#[4 5 5 3 4]\n",
    "#[4 5 7 3 4]\n",
    "#print(np.round(np.max(y_pred,1),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 14, 14, 64)        4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 7, 7, 256)         17216     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 25,674\n",
      "Trainable params: 25,418\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifQGbqS05Rts"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "Carregue a base de dados MNIST do pacote Keras, e pre-processe conforme código abaixo.\n",
    "\n",
    "Vamos utilizar o modelo treinado na questão anterior como forma de trasnferência de aprendizado. Se preciso reinicialize o modelo e treine-o novamente para garantir que apenas 7 épocas foram executadas. O modelo final deve ter acurácia de treinamento próxima a 0.89 (computada na base Fashion). \n",
    "\n",
    "Agora, assuma que esse modelo já treinado está armazenado numa variável `model`. Então proceda da seguinte forma:\n",
    "\n",
    "1. Obtendo a saída da penúltima camada (referente ao Dropout): `base_saida = model.layers[-2].output`\n",
    "2. Criando uma nova camada de saída que recebe como entrada a anterior `saida_nova = keras.layers.Dense(10, activation='softmax')(base_saida)`\n",
    "3. Criando um novo modelo tendo essa nova camada como saída `model2 = keras.models.Model(model.inputs, saida_nova)`\n",
    "\n",
    "Você pode usar o summary para conferir o modelo montado.\n",
    "\n",
    "Agora inicialize as sementes do numpy para 1 e tensorflow para 2, compile e treine o novo modelo com função de custo entropia cruzada categórica, otimizador Adam com taxa de aprendizado 0.002, 16 exemplos no mini-batch e 3 épocas.\n",
    "\n",
    "Avalie a acurácia no conjunto de testes. Em qual intervalo está a acurácia resultante, considerando arredondamento para 2 casas decimais?\n",
    "\n",
    "(a) [0.94,0.96]<br>\n",
    "<font color='red'>(b) [0.98,1.00]<br></font>\n",
    "(c) [0.87,0.90]<br>\n",
    "(d) [0.92,0.93]<br>\n",
    "\n",
    "**Justificativa**: Ver código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K5Owfr6GyqqY",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images2, train_labels2), (test_images2, test_labels2) = mnist.load_data()\n",
    "train_images2 = train_images2 / 255.0\n",
    "test_images2 = test_images2 / 255.0\n",
    "train_labels2 = keras.utils.to_categorical(train_labels2, 10)\n",
    "test_labels2 = keras.utils.to_categorical(test_labels2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "Cz79HkPP5Rtx",
    "outputId": "3a03a7df-6957-484a-f065-911302944376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 14, 14, 64)        4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 7, 7, 256)         17216     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 25,674\n",
      "Trainable params: 25,418\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.1635 - accuracy: 0.9496\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 113s 30ms/step - loss: 0.0681 - accuracy: 0.9783\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 115s 31ms/step - loss: 0.0572 - accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "base_output = model1.layers[-2].output\n",
    "newout = keras.layers.Dense(10, activation='softmax')(base_output)\n",
    "model2 = keras.models.Model(model1.inputs, newout)\n",
    "model2.summary()\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.002),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist2 = model2.fit(train_images2, train_labels2, batch_size=16,\n",
    "                    epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ej_sqivf6DRY",
    "outputId": "1182a5a1-f1c3-41a5-8da8-de69978c9b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia teste: 0.98\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(test_images2, test_labels2, verbose=0)\n",
    "print(\"Acurácia teste: %.2f\" % (scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7nDGxVQMdJFI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Avaliacao_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
