{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo IV - Estratégias de Treinamento e Transferência de Aprendizado</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "### Exercício 1)\n",
    "\n",
    "Em termos do viés do algoritmo de aprendizado, o qual está relacionado ao espaço de funções admissíveis a partir do qual esse algoritmo gera modelos (de classificação, regressão, etc.), como podemos comparar métodos rasos, comumente com poucos parâmetros a ajustar, e profundos, comparativamente possuindo mais parâmetros?\n",
    "\n",
    "(a) Métodos profundos tem viés mais fraco quando comparado ao métodos rasos<br>\n",
    "(b) Métodos profundos tem viés mais forte quando comparado ao métodos rasos<br>\n",
    "(c) Métodos profundos possuem viés enquanto os rasos não possuem viés<br>\n",
    "(d) Métodos profundos não possuem viés enquanto os rasos possuem viés<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 2)\n",
    "\n",
    "Modelos de redes neurais com alta capacidade, isso é, com grande quantidade de parâmetros, são capazes de:\n",
    "\n",
    "(a) Generalizar muito bem sempre, para qualquer tipo de dados futuros<br>\n",
    "(b) Gerar underfitting pois podem não conseguir convergir e portanto não se ajustam aos dados de treinamento<br>\n",
    "(c) Memorizar o conjunto de treinamento, ajustando até mesmo rótulos aleatórios<br>\n",
    "(d) Obter alta robustez com relação à possíveis ataques<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Exercício 3)\n",
    "\n",
    "Métodos diretamente relacionados a evitar que redes neurais profundas convirjam para o modelo \"memorizador\" incluem:\n",
    "\n",
    " (a) Evitar treinar por número de épocas excessivas, técnicas de regularização e obtenção de conjuntos de treinamento maiores<br>\n",
    " (b) Regularização, transferência de aprendizado e emprego de maior número de neurônios por camada<br>\n",
    " (c) Ajustar corretamente o tamanho do batch, utilizar dropout e evitar o uso da função de ativação softmax<br>\n",
    " (d) Regularização, aumento da quantidade de dados de treinamento e uso de funções de ativação do tipo ReLU<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6exl-MrVyqqT"
   },
   "source": [
    "---\n",
    "### Exercício 4)\n",
    "\n",
    "Considere uma base de dados de imagens para treinamento, com 3 classes, e 20 exemplos por classe. Suponha que deseje utilizar uma CNN como solução para obter um classificador para esse problema. Qual das opções abaixo é a mais viável?\n",
    "\n",
    " (a) Carregar um modelo de CNN bem estabelecido, pré-treinado em base de dados grande, obter os mapas de ativação de alguma camada da CNN e utilizar esses mapas como entrada para um classificador com maior garantia de aprendizado, como o SVM<br>\n",
    " (b) Carregar um modelo de CNN bem estabelecido, com pesos inicializados aleatoriamente, obter os mapas de ativação de alguma camada da CNN e utilizar esses mapas como entrada para um classificador com maior garantia de aprendizado, como o SVM<br>\n",
    " (c) Carregar um modelo de CNN bem estabelecido, com pesos inicializados aleatoriamente, projetar uma nova camada de saída densa com 3 neurônios, e treinar apenas essa camada de saída como classificador<br>\n",
    " (d) Carregar um modelo de CNN bem estabelecido, pré-treinado em base de dados grande, projetar uma nova camada de saída densa com 3 neurônios, e treinar toda a CNN com os dados de treinamento, incluindo a nova camada<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfnm0YgLyqqU"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 5)\n",
    "\n",
    "Normalização dos dados entre camadas de uma rede profunda tem a função principal de:\n",
    "\n",
    "(a) Permitir melhor visualização dos mapas de ativação<br>\n",
    "(b) Evitar underfitting gerando magnitudes de gradientes mais extremas<br>\n",
    "(c) Facilitar a convergência suavizando a descida do gradiente e reduzindo o problema de desaparecimento do gradiente<br>\n",
    "(d) Evitar overfitting padronizando os dados do batch aleatoriamente<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6VfUMk8yqqW"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 6)\n",
    "\n",
    "Carregue a base de dados Boston Housing, e padronize os dados (conforme código abaixo). \n",
    "\n",
    "A seguir, considere as seguintes arquitetura de rede neural com camadas densas, todas com **6** neurônios nas camadas intenas/ocultas:\n",
    "\n",
    "Arquitetura A (12 camadas):\n",
    "* 12 camadas densas com ativação `relu`\n",
    "* 1 camada densa com 1 neurônio e ativação `relu`\n",
    "\n",
    "Arquitetura B (12 camadas com normalização em batch):\n",
    "* 2 camadas densas com ativação `relu`\n",
    "* 1 camada de normalização em batch\n",
    "* 2 camadas densas com ativação `relu`\n",
    "* 1 camada de normalização em batch\n",
    "* 2 camadas densas com ativação `relu`\n",
    "* 1 camada de normalização em batch\n",
    "* 2 camadas densas com ativação `relu`\n",
    "* 1 camada de normalização em batch\n",
    "* 2 camadas densas com ativação `relu`\n",
    "* 1 camada de normalização em batch\n",
    "* 2 camadas densas com ativação `relu`\n",
    "* 1 camada densa com 1 neurônio e ativação `relu`\n",
    "\n",
    "Faremos 3 experimentos de treinamento, a partir de 3 configurações de sementes distintas. Dica: monte cada arquitetura em uma função do Python e retorne o modelo para facilitar o processo.\n",
    "\n",
    "Você deverá inicializar as sementes antes de criar cada modelo (A e B) na memória. Logo a seguir, compilar e treinar, passando o conjunto de teste como \"validação\" para verificarmos possíveis problemas de generalização.\n",
    "\n",
    "1. Experimento 1: seed(1) e set_seed(1)\n",
    "2. Experimento 2: seed(2) e set_seed(2)\n",
    "3. Experimento 3: seed(3) e set_seed(3)\n",
    "\n",
    "Em cada experimento, treine as redes A e B com a função de custo `mse`, o otimizador Adam com taxa de aprendizado 0.01, 50 épocas, e tamanho de batch 32. Salve os históricos por época e trace o gráfico da função de custo computada no treinamento e no teste ao longo das épocas dos modelos A e B para cada um dos experimentos. \n",
    "\n",
    "Observando os gráficos dos 3 experimentos, podemos dizer sobre o processo de convergência do valor de custo que:\n",
    "\n",
    "(a) A: convergiu sempre atingindo bons valores de erro médio quadrático; B: convergiu rapidamente sempre, porém com overfitting do modelo em todos os casos<br>\n",
    "(b) A: não convergiu nos experimentos; B: não convergiu nos experimentos<br>\n",
    "(c) A: convergiu rapidamente em todos os experimentos, mas o modelo não melhorou mais o erro após as primeiras épocas; B: não convergiu na maioria dos casos, mas quando convergiu apresentou melhor generalização do que A<br>\n",
    "(d) A: convergiu para um valor baixo de erro, mas não em todos os casos; B: convergiu em todos os casos, ainda que o erro na validação apresente irregularidades<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "fVUByVse5Rs-",
    "outputId": "aa56f877-b1bb-4506-8364-0cb680267b7a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "#normalizacao max-min 0-1\n",
    "maxv = x_train.max(axis=0)\n",
    "minv = x_train.min(axis=0)\n",
    "x_train = (x_train - minv)/(maxv-minv)\n",
    "\n",
    "x_test = (x_test - minv)/(maxv-minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBz3dDiX5RtE"
   },
   "outputs": [],
   "source": [
    "def model_A(neurons, layers):\n",
    "    # seu código\n",
    "    return modelA\n",
    "\n",
    "def model_B(neurons, layers):\n",
    "    # seu código\n",
    "    return modelB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "7T_xLExo5RtL",
    "outputId": "29c65006-3203-479e-94f6-c94293d11052"
   },
   "outputs": [],
   "source": [
    "# experimentos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 7)\n",
    "\n",
    "Considere a mesma base de dados e condições de treinamento (incluindo a inicialização das sementes). Projete uma nova rede neural com o seguinte formato:\n",
    "\n",
    "Arquitetura C (incluindo Dropout):\n",
    "* 1 camada densa com 6 neurônios e ativação `relu`\n",
    "* 1 camada Batch Normalization\n",
    "* 10 camadas densas com 6 neurônios e ativação `relu`\n",
    "* 1 camada Dropout com probabilidade 0.2\n",
    "* 1 camada densa com 6 neurônios e ativação `relu`\n",
    "* 1 camada Dropout com probabilidade 0.5\n",
    "* 1 camada densa com 1 neurônio e ativação `relu`\n",
    "\n",
    "Trace o gráfico da função de custo computada no treinamento e no teste ao longo das épocas. Podemos dizer sobre o processo de convergência do custo que:\n",
    "\n",
    "(a) C: não convergiu na maior parte dos experimentos, indicando que Dropout não foi efetivo em auxiliar no treinamento dessa rede profunda<br>\n",
    "(b) C: apresentou convergência do modelo em todos os casos, com perda na validação similar ou ligeiramente menor do que quando medida no treinamento<br>\n",
    "(c) C: apresentou convergência do modelo em todos os casos, mas com problemas de generalização, pois a perda na validação aumentou consideravelmente ao longo das épocas, em comparação com a perda medida no treinamento<br>\n",
    "(d) C: não convergiu em nenhum dos experimentos, indicando que Dropout não foi efetivo em auxiliar no treinamento dessa rede profunda<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqd_Vgmv5Rtg"
   },
   "outputs": [],
   "source": [
    "### Model C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ng6Q2T-Z5Rtk",
    "outputId": "8f16c455-2600-48d9-96b8-e407fb590ff4"
   },
   "outputs": [],
   "source": [
    "### experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifQGbqS05Rts"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 8)\n",
    "\n",
    "Vamos utilizar imagens da base de dados `cifar10` carregada do TensorFlow Datasets. Considere o código abaixo que carrega essa base de dados (utilizamos um subconjunto de treinamento e validação), e seu posterior processamento. Redimensionamos as imagens para $128\\times 128$ para permitir posterior uso em CNNs pré-treinadas (ver próximo exercício). Note também que é preciso obter codificação one-hot-encoding para as classes pois essa base de dados não é binária. Utilizaremos essa mesma base de dados nos exercícios subsequentes.\n",
    "\n",
    "Utilize a arquitetura \"residual\" proposta no notebook 1 da aula, porém altere para que as camadas residuais tenham 32 filtros (ao invés de 64), e a camada convolucional final tenha 256 (ao invés de 512).\n",
    "\n",
    "Adicione ainda a possibilidade de incluir aumentação de dados como uma camada, logo após a camada de entrada (use um parâmetro augmentation=True/False para ligar e desligar). A aumentação de dados deve conter as seguintes operações (nessa ordem):\n",
    "* RandomFlip(\"horizontal\")\n",
    "* RandomContrast(0.3)\n",
    "* RandomRotation(0.2)\n",
    "\n",
    "Inicialize as sementes do numpy para 1 e tensorflow para 2, e crie, compile e execute um modelo conforme a função definida, utilizando: Dropout com 0.2, BatchNormalization e Augmentation, bem como: função de custo entropia cruzada categórica, otimizador Adam com taxa de aprendizado 0.001 e 64 exemplos no batch. Compute também a acurácia durante o treinamento.\n",
    "\n",
    "Qual foi o intervalo de acurácia no treinamento e validação avaliados (use a função `evaluate`) após o treinamento por 5 épocas?\n",
    "\n",
    "(a) Treinamento=[35,39]; Val=[34,38]<br>\n",
    "(b) Treinamento=[48,50]; Val=[49,53]<br>\n",
    "(c) Treinamento=[59,64]; Val=[50,58]<br>\n",
    "(d) Treinamento=[39,44]; Val=[37,40]<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "K5Owfr6GyqqY",
    "outputId": "b165fd2b-5199-4974-ac64-5a36033cdefe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "(train_ds, validation_ds), info = tfds.load(\n",
    "    \"cifar10\",\n",
    "    split=[\"train[0%:30%]\", \"train[30%:40%]\"],\n",
    "    as_supervised=True, \n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_classes = info.features[\"label\"].num_classes\n",
    "print(\"Classes: \", num_classes)\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "img_size = (128, 128)\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, img_size), y))\n",
    "train_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, img_size), y))\n",
    "validation_ds = validation_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "input_shape = img_size + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "Cz79HkPP5Rtx",
    "outputId": "25a524a2-7ce0-4b6b-a6b8-9817db43db43"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for i, (image, label) in enumerate(train_ds.take(10)):\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkh4C8IF5Rt2"
   },
   "outputs": [],
   "source": [
    "def label_preprocess(image, label):\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "if (num_classes > 2):\n",
    "    train_ds = train_ds.map(\n",
    "        label_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    validation_ds = validation_ds.map(\n",
    "        label_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGz-ejES5Rt4"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtWS110e5Rt8"
   },
   "outputs": [],
   "source": [
    "# camada de aumentacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-6WqQIyyqqk"
   },
   "outputs": [],
   "source": [
    "# def minha_CNN(input_shape, ...):\n",
    "    #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "tiY11n0t5RuD",
    "outputId": "54569edb-3f8f-4d86-a1af-8f134c2fe94d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed(1)\n",
    "set_seed(2)\n",
    "# cria CNN\n",
    "# compila\n",
    "# treina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "Ql8X8sKQeDdh",
    "outputId": "72f9fa9c-7d69-4063-878d-c1fe5a1285bb"
   },
   "outputs": [],
   "source": [
    "# avalia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3zlC0i0yqrX"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 9)\n",
    "\n",
    "Utilize a mesma base de dados, conforme carregada e pré-processada no exercício anterior.\n",
    "\n",
    "Carregue como modelo base a CNN MobileNetV2 (ver https://keras.io/api/applications/) e seus pesos pré-treinados na ImageNet, sendo preparada para receber como entrada imagens no formato da Cifar10.\n",
    "\n",
    "Monte um modelo que possua logo após a entrada, a MobileNetV2 (sem data augmentation), seguida de GlobalAveragePooling2D, Dropout de 0.2 e uma camada densa com ativação Softmax. Torne o modelo base (MobileNetV2) não treinável, treinando apenas a camada Softmax.\n",
    "\n",
    "Inicialize as sementes do numpy para 1 e tensorflow para 2, compile e treine o modelo. \n",
    "\n",
    "Qual foi o intervalo de acurácia no treinamento e validação após o treinamento durante 6 épocas?\n",
    "\n",
    "(a) Treinamento=[76,82]; Val=[74,78]<br>\n",
    "(b) Treinamento=[42,48]; Val=[33,39]<br>\n",
    "(c) Treinamento=[70,78]; Val=[65,70]<br>\n",
    "(d) Treinamento=[59,64]; Val=[32,38]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "c9kP0ofB5RuK",
    "outputId": "1924fe09-f64f-4d7d-85b3-7936368bb2d3"
   },
   "outputs": [],
   "source": [
    "# carrega rede\n",
    "# monta modelo\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "# compila\n",
    "# treina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "-7J7_LnQeyJg",
    "outputId": "166f043a-17aa-4fa9-a329-fd7ce439ce90"
   },
   "outputs": [],
   "source": [
    "# avalia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OLlz13JyqrX"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 10)\n",
    "\n",
    "Similar ao exercício anterior, monte um modelo que possua logo após a entrada, a MobileNetV2 (sem data augmentation), seguida de GlobalAveragePooling2D, Dropout de 0.2 e uma camada densa com ativação Softmax. Torne o modelo base (MobileNetV2) treinável. Observação: recarregue os pesos, não use os pesos utilizados a partir do exercício anterior.\n",
    "\n",
    "Qual foi o intervalo de acurácia no treinamento e validação após o treinamento durante 6 épocas?\n",
    "\n",
    "(a) Treinamento=[59,65]; Val=[70,76]<br>\n",
    "(b) Treinamento=[75,84]; Val=[75,78]<br>\n",
    "(c) Treinamento=[88,90]; Val=[32,38]<br>\n",
    "(d) Treinamento=[92,97]; Val=[78,87]<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "SZr1QQF2XYEJ",
    "outputId": "c3ae8a4c-f98b-40be-fec8-df862e80318f"
   },
   "outputs": [],
   "source": [
    "# carrega rede\n",
    "# monta modelo\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "# compila\n",
    "# treina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "ej_sqivf6DRY",
    "outputId": "33e685f4-3746-415c-9a6b-4b85da5f2745"
   },
   "outputs": [],
   "source": [
    "# avalia"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Exercicios_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
