{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo IV - Estratégias de Treinamento e Transferência de Aprendizado</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "As respostas devem ser dadas no Moodle, use esse notebook apenas para gerar o código necessário para obter as respostas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "\n",
    "### Questão 1)\n",
    "\n",
    "Qual a relação entre o modelo chamado de \"memorizador\" e as redes neurais profundas?\n",
    "\n",
    "(a) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, tornando-as hábeis para generalizar para dados futuros.<br>\n",
    "(b) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, falhando em predizer corretamente exemplos não vistos.<br>\n",
    "(c) Redes neurais com alta capacidade são imunes a convergir para modelos memorizadores, pois obtiveram resultados do estado-da-arte em muitas aplicações.<br>\n",
    "(d) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, e portanto possuem viés forte.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 2)\n",
    "\n",
    "O papel do uso conjunto dos métodos BatchNormalization e Regularização é o de:\n",
    "\n",
    "(a) Pré-processamento dos dados antes da realização do treinamento<br>\n",
    "(b) Gerar espaço de parâmetros esparsos, com alguns poucos parâmetros com valor alto e muitos com valores próximo a zero, melhorando a generalização<br>\n",
    "(c) Minimizar o problema do desaparecimento do gradiente, e ao mesmo tempo evitar que poucas unidades/neurônios se especializem demais<br>\n",
    "(d) Obter robustez com relação à possíveis ataques e propiciar modelos menores com acurácia similar a modelos maiores<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Questão 3)\n",
    "\n",
    "São práticas viáveis para o uso de aprendizado profundo com pequenas bases de dados:\n",
    "\n",
    " (a) Carregar uma rede neural profunda popular de um pacote de software e treiná-la a partir de pesos aleatórios<br>\n",
    " (b) Carregar uma rede neural profunda pré-treinada em grande base de dados, e utilizar a saída da última camada  da rede, ou seja as predições das classes, como característica para modelos de aprendizado externos que permitem uso com menores bases de dados<br>\n",
    " (c) Carregar uma rede neural profunda popular de um pacote de software e treiná-la a partir de pesos aleatórios utilizando Batch Normalization<br>\n",
    " (d) Carregar uma rede neural profunda pré-treinada em grande base de dados, inserindo uma nova camada de saída treinando apenas essa camada com a pequena base de dados<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Carregue a base de dados Fashion MNIST conforme código abaixo e crie um modelo de CNN com a seguinte arquitetura, capaz de obter classificação nessa base de dados de imagens. Considere que todas as camadas convolucionais tem zeropadding, e ativação relu, exceto quando mencionado contrário.\n",
    "\n",
    "1. Pré-processamento para aumentação contendo:\n",
    "  * RandomZoom(0.1),\n",
    "  * RandomContrast(0.2)\n",
    "1. Convolucional 2D com 64 filtros $3\\times 3$.\n",
    "2. Batch Normalization\n",
    "3. SeparableConv2D com 64 filtros $3\\times 3$.\n",
    "4. MaxPooling2D $3\\times 3$ e strides $2$\n",
    "5. Batch Normalization\n",
    "6. SeparableConv2D com 256 filtros $3\\times 3$.\n",
    "7. MaxPooling2D $3\\times 3$ e strides $2$\n",
    "8. GlobalAveragePooling\n",
    "9. Dropout de 0.2\n",
    "10. Densa com ativação softmax\n",
    "\n",
    "Incialize as sementes do numpy com 1 e tensorflow com 2 e treine o modelo por 7 épocas com batch size 16, otimizador Adam e taxa de aprendizado 0.002.\n",
    "\n",
    "Após o treinamento utilize a função predict para classificar imagens da posicao 10 a 14 no conjunto de testes ([10:15]). Quais as classes resultantes e quantas dessas estavam erradas?\n",
    "\n",
    "(a) 2, 5, 5, 3, 3, sendo 2 erradas<br>\n",
    "(b) 4, 5, 5, 3, 4, sendo 2 erradas<br>\n",
    "(c) 4, 5, 5, 3, 4 sendo 1 errada<br>\n",
    "(d) 4, 5, 5, 3, 4, nenhuma errada<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rif40G6wST-s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VFB_hc7PC0e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "YpiKc7c6P39d",
    "outputId": "dcd70326-21e4-40d9-8803-80e0abecdba8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifQGbqS05Rts"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "Carregue a base de dados MNIST do pacote Keras, e pre-processe conforme código abaixo.\n",
    "\n",
    "Vamos utilizar o modelo treinado na questão anterior como forma de trasnferência de aprendizado. Se preciso reinicialize o modelo e treine-o novamente para garantir que apenas 7 épocas foram executadas. O modelo final deve ter acurácia de treinamento próxima a 0.89 (computada na base Fashion). \n",
    "\n",
    "Agora, assuma que esse modelo já treinado está armazenado numa variável `model`. Então proceda da seguinte forma:\n",
    "\n",
    "1. Obtendo a saída da penúltima camada (referente ao Dropout):\n",
    "\n",
    "`base_saida = model.layers[-2].output`\n",
    "\n",
    "2. Criando uma nova camada de saída que recebe como entrada a anterior \n",
    "\n",
    "`saida_nova = keras.layers.Dense(10, activation='softmax')(base_saida)`\n",
    "\n",
    "3. Criando um novo modelo tendo essa nova camada como saída \n",
    "\n",
    "`model2 = keras.models.Model(model.inputs, saida_nova)`\n",
    "\n",
    "Você pode usar o summary para conferir o modelo montado.\n",
    "\n",
    "Agora inicialize as sementes do numpy para 1 e tensorflow para 2, compile e treine o novo modelo com função de custo entropia cruzada categórica, otimizador Adam com taxa de aprendizado 0.002, 16 exemplos no mini-batch e 3 épocas.\n",
    "\n",
    "Avalie a acurácia no conjunto de testes. Em qual intervalo está a acurácia resultante, considerando arredondamento para 2 casas decimais?\n",
    "\n",
    "(a) [0.94,0.96]<br>\n",
    "(b) [0.98,1.00]<br>\n",
    "(c) [0.87,0.90]<br>\n",
    "(d) [0.92,0.93]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "K5Owfr6GyqqY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images2, train_labels2), (test_images2, test_labels2) = mnist.load_data()\n",
    "train_images2 = train_images2 / 255.0\n",
    "test_images2 = test_images2 / 255.0\n",
    "train_labels2 = keras.utils.to_categorical(train_labels2, 10)\n",
    "test_labels2 = keras.utils.to_categorical(test_labels2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "Cz79HkPP5Rtx",
    "outputId": "3a03a7df-6957-484a-f065-911302944376"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Avaliacao_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
