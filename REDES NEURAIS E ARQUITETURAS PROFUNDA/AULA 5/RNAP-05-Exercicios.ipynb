{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo V - Redes neurais auto-associativas e geradoras</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "### Exercício 1)\n",
    "\n",
    "Auto-encoders são apropriados para tarefas de aprendizado não supervisionado, em que os dados de entrada são reconstruídos e uma representação compacta destes dados é aprendida. Em relação a esse método, qual afirmação está incorreta?\n",
    "\n",
    "a) A função de custo Mean Square Error deve ser utilizada com o propósito de medir a eficiência do aprendizado da rede, em que se considera seu potencial de obter imagens com alto grau de similaridade em relação às imagens de entrada.\n",
    "\n",
    "b) Podemos utilizar um auto-encoder para ser treinado com exemplos não rotulados e reaproveitar somente o Encoder para formar uma CNN com adição de novas camadas para a predição com posterior fine-tuning. \n",
    "\n",
    "c) Auto-encoders overcomplete obtém naturalmente códigos compactos e de baixa dimensionalidade, similar a projeção PCA nos principais componentes considerando dimensionalidade menor do que a da entrada.\n",
    "\n",
    "d) Denoising auto-encoderes são arquiteturas que podem ser utilizadas para duas tarefas simultaneamente após o seu treinamento. O primeiro deles é fornecer espaço de características que representam um conjunto de dados. O segundo propósito é funcionar como um filtro para remoção de ruídos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 2)\n",
    "\n",
    "É correto afirmar sobre a principal tarefa realizada pela família de métodos do tipo Autoencoder\n",
    "\n",
    "(a) Mapeia os dados de entrada em um espaço latente que melhor permita uma boa classificação dos dados de treinamento, sendo o foco principal do aprendizado aumento de acurácia<br>\n",
    "(b) Mapeia os dados de entrada em um espaço latente, e posteriormente aprende uma reconstrução desse espaço latente novamente no espaço de entrada, sendo o foco principal do aprendizado obter um espaço latente compacto e representativo.<br>\n",
    "(c) Mapeia os dados de entrada no espaço de saída num problema similar à regressão, em que temos informações a priori sobre como reconstruir os dados de entrada<br>\n",
    "(d) Mapeia os dados de entrada com principal objetivo de eliminar o ruído dos dados e portanto é útil para tarefas de limpeza de dados. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Exercício 3)\n",
    "\n",
    "Considere os métodos Autoencoder, Denoising Autoencoder e Variational Autoencoder. Podemos dizer que esses métodos se enquadram em qual tipo de aprendizado?\n",
    "\n",
    " (a) Supervisionado<br>\n",
    " (b) Semi-supervisionado<br>\n",
    " (c) Não supervisionado<br>\n",
    " (d) Fracamente supervisionado<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6exl-MrVyqqT"
   },
   "source": [
    "---\n",
    "### Exercício 4)\n",
    "\n",
    "Você treinou uma GAN, porém enquanto a perda do discriminador esteve sempre decrescente a perda do gerador cresceu no treino. Qual dos procedimentos abaixo tem a **menor** chance de auxiliar no treinamento:\n",
    "\n",
    "a) Reduzir a taxa de aprendizado do discriminador<br>\n",
    "b) Aumentar a capacidade do discriminador e reduzir a do gerador<br>\n",
    "c) Regularizar ou aumentar a regularização do discriminador<br>\n",
    "d) Fazer mais de uma atualização do gerador para cada atualização dos pesos do discriminador<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5)\n",
    "\n",
    "Em geral qual modelo: Variational Autoencoder (VAE) ou Generative Adversarial Network (GAN) é mais difícil de treinar e por que?\n",
    "\n",
    "a) GANs, pois estamos tentando otimizar 2 modelos simultâneamente e de forma adversarial<br>\n",
    "b) VAEs, pois sua perda é complexa de calcular<br>\n",
    "c) GANs, pois necessitam de muita aumentação de dados<br>\n",
    "d) VAEs, pois precisam aprender distribuições de dados para dois modelos (encoder e decoder)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfnm0YgLyqqU"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 6)\n",
    "\n",
    "Carregue a base de dados `smartphone_activity_dataset.csv`, que possui 6 classes, conforme abaixo. Utilizaremos os primeiros 70% exemplos como treinamento e o restante como teste.\n",
    "\n",
    "Defina as sementes `seed(1)` e `set_seed(2)`. Logo após, projete e instancie um Encoder com as seguintes camadas, sendo que, após a entrada, todas terão ativação tangente hiperbólica:\n",
    "* Entrada\n",
    "* Densa com metade das dimensões da entrada (use a divisão inteira //2)\n",
    "* Densa com um quarto das dimensões da entrada (use a divisão inteira //4)\n",
    "* Densa com 32 dimensões\n",
    "\n",
    "Sem realizar treinamento, passe os dados de treinamento e teste pela rede, obtendo as ativações da última camada, com 32 dimensões.\n",
    "\n",
    "Carregue o classificador SVC da biblioteca sklearn, e treine com parâmetros C=1, random_state=1, com as características obtidas da rede neural de treinamento, realizando a predição no teste a seguir, medindo a acurácia por meio da função score.\n",
    "\n",
    "Qual foi o resultado de acurácia obtido?\n",
    "\n",
    "(a) Acurácia de um classificador aleatório<br>\n",
    "(b) Acurácia abaixo de 5%<br>\n",
    "(c) Acurácia no intervalo entre 45% e 65%<br>\n",
    "<font color='red'>(d) Acurácia acima de 75%<br></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"smartphone_activity_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotulos = np.array(df['activity'])\n",
    "features = np.array(df.iloc[:, :-1])\n",
    "\n",
    "print(features.shape)\n",
    "perc_train = 0.7\n",
    "\n",
    "n_train = int(features.shape[0]*perc_train)\n",
    "n_test = int(features.shape[0]*(1-perc_train))\n",
    "print(n_train)\n",
    "print(n_test)\n",
    "\n",
    "x_train = features[:n_train,:]\n",
    "y_train = rotulos[:n_train]\n",
    "\n",
    "x_test = features[n_train:,:]\n",
    "y_test = rotulos[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### autoencoder\n",
    "### projecao sem treinamento\n",
    "### treinamento SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6VfUMk8yqqW"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 7)\n",
    "\n",
    "Uso de GANs para aprendizado de representações. Utilizando a mesma base de dados do exercício anterior, projete e treine uma GAN para gerar exemplos artificiais da base de dados `smartphone_activity_dataset.csv`. Utilizaremos todos os exemplos para treinamento da GAN.\n",
    "\n",
    "Para isso, utilize a GAN proposta em aula conforme o código abaixo, alterada conforme o código abaixo e as seguintes configurações:\n",
    "* discriminador com uma camada oculta com 32 dimensões (utilize o parâmetro `name='embedding'` nessa camada para facilitar seu uso posterior), deve ser treinado com Adam e taxa de aprendizado 0.0001 (apenas para o discriminador)\n",
    "* gerador com 2 camadas ocultas com 256 neurônios\n",
    "* dimensão de z = 256\n",
    "* dimensão de entrada igual a da base de dados\n",
    "* função de distribuição alvo deve amostrar da base de dados\n",
    "\n",
    "Todas as camadas serão `tanh` exceto a camada de saída do discriminador que é `sigmoid`.\n",
    "\n",
    "Treine a GAN por 1000 épocas com batch size 32 e otimizador Adam com lr=0.001.\n",
    "\n",
    "Após, utilize a camada \"embedding\" do discriminador como extratora de características, passando os dados da base de treinamento e teste (na mesma divisão feita na questão anterior) para o discriminador, e pegando a projeção feita pela camada densa. \n",
    "\n",
    "Treine classificadores SVM com parâmetros C=1 e random_state=1, um na base de dados com suas características originais, e o outro nas característias do \"embedding\" do discriminador. Obtenha o score nos respectivos conjuntos de teste. Os resultados estão em qual intervalo? \n",
    "\n",
    "(a) Original = [92,97], Embedding 32d GAN = [88,92], a GAN foi capaz de aprender uma boa representação compacta com acurácia próxima da original sendo a quantidade de épocas suficiente para esse aprendizado<br>\n",
    "(b) Original = [85,88], Embedding 32d GAN = [85,88], a GAN produz representação similar aos dados originais, porém com menor dimensionalidade, indicando que houve convergência<br>\n",
    "(c) Original = [92,97], Embedding 32d GAN = [10,20], a GAN gera uma representação que produz classificação próxima da aleatória<br>\n",
    "(d)  Original = [92,97], Embedding 32d GAN = [79,82], a GAN gera uma representação compacta com resultado abaixo da original, sendo necessário executar por mais épocas para investigar se é capaz de gerar uma representação mais fiel aos dados<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## funcoes discriminador, gerador e amostragem de exemplos falsos/verdadeiros\n",
    "\n",
    "# modelo discriminador base : classificador\n",
    "def discriminator(dim_input=2, embedding_size=128):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(embedding_size, activation='tanh', name='embedding', input_dim=dim_input))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def distribuicao_alvo(n, x_train):\n",
    "    labels_reais = np.ones((n,1))\n",
    "    return x_train[np.random.choice(x_train.shape[0], n, replace=False), :], labels_reais\n",
    "\n",
    "# modelo gerador, cuja entrada tem dimensão do espaço latente\n",
    "# sua saída tem dimensão igual a dos exemplos da distribuição alvo\n",
    "def generator(z_dim, dim_output=2, embedding_size1=256, embedding_size2=256):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(embedding_size1, activation='tanh', name='embedding1', input_dim=z_dim))\n",
    "    model.add(layers.Dense(embedding_size2, activation='tanh', name='embedding2'))\n",
    "    model.add(layers.Dense(dim_output, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# funcao para gerar uma amostra com n exemplos da distribuicao latente\n",
    "def amostra_distribuicao_latente(z_dim, n):\n",
    "    exemplos_z = np.random.randn(z_dim * n)\n",
    "    return exemplos_z.reshape(n, z_dim)\n",
    "\n",
    "# funcao para gerar exemplos \"falsos\", aleatorios a partir da\n",
    "# saída do gerador G(z)\n",
    "def gera_exemplos_falsos(model_g, z_dim, n):\n",
    "    exemplos_z = amostra_distribuicao_latente(z_dim, n)\n",
    "    exemplos_falsos = model_g.predict(exemplos_z)\n",
    "    labels_falsos = np.zeros((n,1))\n",
    "    return exemplos_falsos, labels_falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "fVUByVse5Rs-",
    "outputId": "aa56f877-b1bb-4506-8364-0cb680267b7a"
   },
   "outputs": [],
   "source": [
    "## funcao para o modelo e treinamento da GAN\n",
    "\n",
    "## instanciamento do discriminador, gerador e GAN\n",
    "\n",
    "## treinamento GAN\n",
    "\n",
    "## uso do embedding GAN para treinar SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 8)\n",
    "\n",
    "Interpolação utilizando código autoencoder. \n",
    "\n",
    "Crie um Autoencoder profundo do tipo Denoising Undercomplete para imagens da base de dados MNIST.\n",
    "\n",
    "Para tornar o treinamento mais rápido utilizaremos apenas as 3000 primeiras imagens da base de dados de treinamento. Crie uma versão ruidosa do conjunto de treinamento conforme indicado no código.\n",
    "\n",
    "O Autoencoder deve possuir a seguinte arquitetura no encoder (todas as camadas com ativação relu):\n",
    "\n",
    "* Conv2D com 32 filtros 3x3, strides 2, zeropadding\n",
    "* Conv2D com 32 filtros 3x3, strides 2, sem zeropadding\n",
    "* MaxPooling2D com poolsize=2\n",
    "* Densa com 32 dimensões (utilize name='code' para facilitar)\n",
    "\n",
    "A seguir, deve possuir um decoder espelhado, resultando na saida de mesma dimensão da entrada.\n",
    "\n",
    "Antes de instanciar o modelo, inicialize as sementes com seed(1), set_seed(2). Depois, compile e treine com perda MSE, Otimizador SGD, taxa 0.01, momentum 0.95, por 25 épocas com batchsize 32.\n",
    "\n",
    "Vamos agora obter interpolações de imagens utilizando os seus códigos. Para isso crie dois modelos, com base no treinado:\n",
    "\n",
    "1. Encoder, que permite recuperar o código de uma imagem (camada 'code')\n",
    "2. Decoder, que permite receber um código e retornar uma imagem\n",
    "\n",
    "O segundo é mais complexo, exige que seja feita a montagem das camadas utilizando a seguinte instrução (estude com calma para entender):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cria nova camada de entrada para receber dimensionalidade do código\n",
    "#input_code_layer = keras.layers.Input(shape=(code_dim))\n",
    "\n",
    "## encadeia camadas a partir de 'inicio', nesse caso 6 - ajuste conforme necessário\n",
    "#inicio = 6\n",
    "#x = input_code_layer\n",
    "#for layer in convae.layers[inicio:]:\n",
    "#    x = layer(x)\n",
    "    \n",
    "#decoder = keras.models.Model(inputs=input_code_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenha as imagens de teste de índice 128 e 198, e então:\n",
    "1. calcule seus códigos pelo encoder: code128 e code198;\n",
    "2. gere interpolações 10 lineares entre code128 e code198 combinando linearmente cada dimensão do vetor com ponderações entre 0 (que resulta apenas na imagem 128) e 1 (que resulta apenas na imagem 198);\n",
    "3. passe cada vetor interpolado pelo decoder, obtendo imagens intermediárias;\n",
    "\n",
    "OBS: os modelos esperam arrays em formatos específicos para predição, para passar uma única imagem use `model.predict(np.array([x_test[indice_imagem],]))`\n",
    "\n",
    "Quais das imagens abaixo foi obtida?\n",
    "\n",
    "\n",
    "(a) <img src=\"ex5_8_alternativa_a.png\" width=620></img><br>\n",
    "(b) <img src=\"ex5_8_alternativa_b.png\" width=620></img><br>\n",
    "(c) <img src=\"ex5_8_alternativa_c.png\" width=620></img><br>\n",
    "(d) <img src=\"ex5_8_alternativa_d.png\" width=620></img><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqd_Vgmv5Rtg"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# os pixels das imagens sao reescalados para melhor processamento\n",
    "# em particular divide-se por 255 para que os valores fiquem entre 0 e 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "print('Dataset size:')\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
    "input_shape = (img_rows, img_cols, 1, )\n",
    "n_classes = 10\n",
    "\n",
    "n=10\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "noisy_train = x_train[:3000] + np.random.random(x_train[:3000].shape)*0.3\n",
    "\n",
    "n=10\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(noisy_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## projeta e treina autoencoder\n",
    "## monta modelo que aproveita apenas encoder\n",
    "## monta modelo que aproveita apenas decoder\n",
    "## obtem encoding para as imagens\n",
    "## processa encodings por interpolacao, passando para o decoder\n",
    "## visualiza imagens reconstruídas"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Exercicios_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
