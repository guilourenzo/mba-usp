{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTFri0e0U30D"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo 5 - Redes neurais auto-associativas e geradoras\n",
    "</span>\n",
    "\n",
    "#### <span style=\"color:darkred\">**Parte 2: Autoencoders para Redução de Dimensionalidade**</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qrrh8BDClsBp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcwcXH7rvCkp"
   },
   "source": [
    "Outra aplicação de auto-encoders é seu uso para **redução de dimensionalidade não supervisionada**\n",
    "\n",
    "Vamos utilizar a base de dados Boston Housing e a tarefa de regressão\n",
    "\n",
    "Essa base de dados possui 13 atributos originalmente, vamos aprender uma redução desse espaço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "p4HSf5-mu642",
    "outputId": "9b0df50d-b138-4e98-cd69-a61dc6cd1b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data()\n",
    "\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "\n",
    "x_test -= mean\n",
    "x_test /= std\n",
    "print(x_test.shape)\n",
    "\n",
    "target_dimensions = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OutVvydqnCKU"
   },
   "source": [
    "### O autoencoder será denso, com:\n",
    "\n",
    "* uma camada de 10 dimensões intermediária (para o encoder e o decoder)\n",
    "* a camada de projeção no espaco do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "_8Blf_vo7__R",
    "outputId": "9ac761d3-7a89-4b5d-d063-9c11a94be803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                143       \n",
      "=================================================================\n",
      "Total params: 419\n",
      "Trainable params: 419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = keras.layers.Input(shape=(13,))\n",
    "\n",
    "# encoder\n",
    "e1 = keras.layers.Dense(10, activation='tanh')(input_data)\n",
    "z = keras.layers.Dense(target_dimensions, activation='tanh')(e1)\n",
    "\n",
    "# decoder\n",
    "d1 = keras.layers.Dense(10, activation='tanh')(z)\n",
    "output = keras.layers.Dense(13, activation='tanh')(d1)\n",
    "\n",
    "autoencoder = keras.models.Model(input_data, output)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BTAFQykeqd93",
    "outputId": "12767c7b-4a05-4a8f-b614-3d86fe15182f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.9225\n",
      "Epoch 2/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6409\n",
      "Epoch 3/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5056\n",
      "Epoch 4/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4473\n",
      "Epoch 5/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4138\n",
      "Epoch 6/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3929\n",
      "Epoch 7/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3781\n",
      "Epoch 8/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3673\n",
      "Epoch 9/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3588\n",
      "Epoch 10/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3515\n",
      "Epoch 11/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3457\n",
      "Epoch 12/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3401\n",
      "Epoch 13/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3352\n",
      "Epoch 14/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3312\n",
      "Epoch 15/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3275\n",
      "Epoch 16/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3241\n",
      "Epoch 17/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3217\n",
      "Epoch 18/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 19/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3169\n",
      "Epoch 20/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3151\n",
      "Epoch 21/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3135\n",
      "Epoch 22/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3120\n",
      "Epoch 23/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3106\n",
      "Epoch 24/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3089\n",
      "Epoch 25/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3079\n",
      "Epoch 26/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3067\n",
      "Epoch 27/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3055\n",
      "Epoch 28/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3045\n",
      "Epoch 29/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3037\n",
      "Epoch 30/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3027\n",
      "Epoch 31/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3017\n",
      "Epoch 32/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3010\n",
      "Epoch 33/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3002\n",
      "Epoch 34/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2997\n",
      "Epoch 35/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2988\n",
      "Epoch 36/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2985\n",
      "Epoch 37/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2974\n",
      "Epoch 38/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2970\n",
      "Epoch 39/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2968\n",
      "Epoch 40/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2956\n",
      "Epoch 41/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2952\n",
      "Epoch 42/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2942\n",
      "Epoch 43/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2942\n",
      "Epoch 44/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2936\n",
      "Epoch 45/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2932\n",
      "Epoch 46/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2926\n",
      "Epoch 47/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2925\n",
      "Epoch 48/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2929\n",
      "Epoch 49/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2917\n",
      "Epoch 50/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2915\n",
      "Epoch 51/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2901\n",
      "Epoch 52/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2899\n",
      "Epoch 53/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2894\n",
      "Epoch 54/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2893\n",
      "Epoch 55/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2891\n",
      "Epoch 56/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2887\n",
      "Epoch 57/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2886\n",
      "Epoch 58/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 59/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 60/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2880\n",
      "Epoch 61/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2878\n",
      "Epoch 62/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2877\n",
      "Epoch 63/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2875\n",
      "Epoch 64/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2874\n",
      "Epoch 65/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2872\n",
      "Epoch 66/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2870\n",
      "Epoch 67/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2869\n",
      "Epoch 68/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2867\n",
      "Epoch 69/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2865\n",
      "Epoch 70/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2864\n",
      "Epoch 71/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2864\n",
      "Epoch 72/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2861\n",
      "Epoch 73/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2861\n",
      "Epoch 74/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2858\n",
      "Epoch 75/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2856\n",
      "Epoch 76/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 77/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2853\n",
      "Epoch 78/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2851\n",
      "Epoch 79/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2848\n",
      "Epoch 80/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2850\n",
      "Epoch 81/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2847\n",
      "Epoch 82/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2846\n",
      "Epoch 83/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2844\n",
      "Epoch 84/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2843\n",
      "Epoch 85/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2841\n",
      "Epoch 86/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2841\n",
      "Epoch 87/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2839\n",
      "Epoch 88/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2836\n",
      "Epoch 89/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2837\n",
      "Epoch 90/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2835\n",
      "Epoch 91/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2835\n",
      "Epoch 92/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2833\n",
      "Epoch 93/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2829\n",
      "Epoch 94/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2828\n",
      "Epoch 95/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2827\n",
      "Epoch 96/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2827\n",
      "Epoch 97/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2825\n",
      "Epoch 98/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 99/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 100/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 101/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2819\n",
      "Epoch 102/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2818\n",
      "Epoch 103/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2817\n",
      "Epoch 104/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2817\n",
      "Epoch 105/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2816\n",
      "Epoch 106/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2816\n",
      "Epoch 107/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 108/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 109/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 110/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 111/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2809\n",
      "Epoch 112/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2809\n",
      "Epoch 113/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2806\n",
      "Epoch 114/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2806\n",
      "Epoch 115/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2805\n",
      "Epoch 116/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2804\n",
      "Epoch 117/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2803\n",
      "Epoch 118/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2802\n",
      "Epoch 119/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2801\n",
      "Epoch 120/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2801\n",
      "Epoch 121/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 122/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 123/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2797\n",
      "Epoch 124/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 125/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 126/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 127/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2794\n",
      "Epoch 128/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2794\n",
      "Epoch 129/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2793\n",
      "Epoch 130/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2792\n",
      "Epoch 131/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2790\n",
      "Epoch 132/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2790\n",
      "Epoch 133/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2789\n",
      "Epoch 134/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2788\n",
      "Epoch 135/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2789\n",
      "Epoch 136/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2787\n",
      "Epoch 137/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2786\n",
      "Epoch 138/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2786\n",
      "Epoch 139/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2785\n",
      "Epoch 140/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2786\n",
      "Epoch 141/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2784\n",
      "Epoch 142/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2783\n",
      "Epoch 143/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2784\n",
      "Epoch 144/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2783\n",
      "Epoch 145/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2781\n",
      "Epoch 146/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2780\n",
      "Epoch 147/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2780\n",
      "Epoch 148/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2780\n",
      "Epoch 149/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2779\n",
      "Epoch 150/150\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2779\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_seed(1)\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 8\n",
    "\n",
    "# definindo um decaimento para a taxa de aprendizado\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 50:\n",
    "    return lr\n",
    "  else:\n",
    "    return np.clip(lr * tf.math.exp(-0.01), 0.00001, 0.001)\n",
    "\n",
    "callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "autoencoder.compile(loss='mse',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.002))\n",
    "\n",
    "hist_ae = autoencoder.fit(x_train, x_train,  \n",
    "                    callbacks=[callbacklr], batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9T5X5s1njuE"
   },
   "source": [
    "---\n",
    "\n",
    "### Uso em regressor externo\n",
    "\n",
    "Com o AE treinado, podemos utilizá-lo para obter representações para instâncias do treinamento e do teste\n",
    "\n",
    "Vamos compara esse novo espaço aprendido com o original e com uma projeção PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SdtavPi_xIcn"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "ht9DvNOJxKRu",
    "outputId": "43542ea0-b5b6-48b3-94e3-e67020df9a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size =  (404, 6)\n",
      "Testing data size =  (102, 6)\n"
     ]
    }
   ],
   "source": [
    "code_model = keras.models.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('dense_1').output)\n",
    "code_train = np.asarray(code_model.predict(x_train))\n",
    "code_test  = np.asarray(code_model.predict(x_test))\n",
    "print(\"Training data size = \", code_train.shape)\n",
    "print(\"Testing data size = \", code_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP-W5nfmn0oM"
   },
   "source": [
    "Criando a projeção PCA para comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ypq2b6Nt5SMf"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=target_dimensions)\n",
    "pca.fit(x_train)\n",
    "pca_train = pca.transform(x_train)\n",
    "pca_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRXkXORfn3ab"
   },
   "source": [
    "Treinando os regressores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "I2c1pJUQxL5A",
    "outputId": "7cec8e4e-bd0d-4938-de1d-52e40c0ccdbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Regressor com Código AE...\n"
     ]
    }
   ],
   "source": [
    "print('Treinando Regressor com Código AE...')\n",
    "clf_ae = Ridge()\n",
    "clf_ae.fit(code_train, y_train)\n",
    "code_pred = clf_ae.predict(code_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Ph1kkYhm4a_0",
    "outputId": "ae5bbb19-1698-41ac-891f-0d657c7709ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Regressor com PCA...\n"
     ]
    }
   ],
   "source": [
    "print('Treinando Regressor com PCA...')\n",
    "clf_pca = Ridge()\n",
    "clf_pca.fit(pca_train, y_train)\n",
    "pca_pred = clf_pca.predict(pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ht34RrU_5hWv",
    "outputId": "d1da0a31-00cb-416f-f5cb-2220938462e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Regressor com Dados Originais...\n"
     ]
    }
   ],
   "source": [
    "print('Treinando Regressor com Dados Originais...')\n",
    "clf_ori = Ridge()\n",
    "clf_ori.fit(x_train, y_train)\n",
    "y_pred = clf_ori.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "6ubbvdgJ_gGg",
    "outputId": "c78c4dc2-3f1b-402a-e311-480e0709cf16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando score...\n",
      "\n",
      "score original: 23.11\n",
      "\n",
      "score PCA: 21.63\n",
      "\n",
      "score AE: 20.46 \n"
     ]
    }
   ],
   "source": [
    "print('Calculando score...')\n",
    "score_ae = mean_squared_error(code_pred, y_test)\n",
    "score_ori = mean_squared_error(y_pred, y_test)\n",
    "score_pca = mean_squared_error(pca_pred, y_test)\n",
    "print('\\nscore original: %.2f' % (score_ori))\n",
    "print('\\nscore PCA: %.2f' % (score_pca))\n",
    "print('\\nscore AE: %.2f ' % (score_ae))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-05-Aula_notebook2_autoencoder_reducao.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
