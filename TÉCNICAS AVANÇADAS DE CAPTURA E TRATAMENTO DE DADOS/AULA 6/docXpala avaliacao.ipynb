{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> MBA em Ciência de Dados</span>\n",
    "# <span style=\"color:blue\">Técnicas Avançadas para Captura e Tratamento de Dados</span>\n",
    "\n",
    "## <span style=\"color:blue\"> Matriz Documento $\\times$ Palavras - Bag of Words</span>\n",
    "    \n",
    "## <span style=\"color:blue\">Avaliação</span>\n",
    "\n",
    "**Material Produzido por Luis Gustavo Nonato**<br>\n",
    "**Cemeai - ICMC/USP São Carlos**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os exercícios abaixo fazem uso da coleção de documentos presente no diretório `DocCol2` contido no arquivo <font style=\"font-family: monaco\"> DocCol.zip</font>, o qual pode ser baixado do Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1)\n",
    "Armazene os documentos disponíveis no diretório `DocCol2` em um dicionário onde a chave é o nome do arquivo e o valor é a string contida no arquivo. O documento contendo a string com o maior número de caracteres é:\n",
    "\n",
    "a) gr7<br>\n",
    "b) au2 <br>\n",
    "c) ch5<br>\n",
    "d) au8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dict_keys(['au1', 'au10', 'au11', 'au12', 'au13', 'au14', 'au15', 'au2', 'au3', 'au4', 'au5', 'au6', 'au7', 'au8', 'au9', 'ch1', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch16', 'ch17', 'ch18', 'ch19', 'ch2', 'ch20', 'ch21', 'ch22', 'ch23', 'ch24', 'ch25', 'ch26', 'ch27', 'ch28', 'ch29', 'ch3', 'ch30', 'ch31', 'ch32', 'ch33', 'ch34', 'ch35', 'ch36', 'ch37', 'ch38', 'ch39', 'ch4', 'ch40', 'ch41', 'ch42', 'ch43', 'ch44', 'ch45', 'ch46', 'ch47', 'ch48', 'ch49', 'ch5', 'ch50', 'ch6', 'ch7', 'ch8', 'ch9', 'gr1', 'gr10', 'gr11', 'gr12', 'gr13', 'gr14', 'gr15', 'gr16', 'gr17', 'gr18', 'gr19', 'gr2', 'gr20', 'gr21', 'gr22', 'gr23', 'gr24', 'gr25', 'gr26', 'gr3', 'gr4', 'gr5', 'gr6', 'gr7', 'gr8', 'gr9'])\n"
    }
   ],
   "source": [
    "# Lendo o documento como uma string\n",
    "import glob  # glob é um pacote que permite varrer arquivos e \n",
    "             # diretorios utilizando sintaxe linux\n",
    "\n",
    "files = glob.glob(\"DocCol2/*\")\n",
    "\n",
    "docs = {}\n",
    "for fname in files:\n",
    "    with open(fname,'r') as f:\n",
    "        key = (fname.split('/')[-1]).replace('DocCol2\\\\','')\n",
    "        docs[key] = f.read() \n",
    "        \n",
    "print(docs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "au2 11672\n"
    }
   ],
   "source": [
    "valor = 0\n",
    "chave = ''\n",
    "\n",
    "for key, values in docs.items():\n",
    "    # print(len(values))\n",
    "    if len(values) > valor:\n",
    "        valor = len(values)\n",
    "        chave = key\n",
    "\n",
    "print(chave, valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA:<br>\n",
    "**LETRA B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2)\n",
    "Crie um dicionário chamado `docsXwords` onde as chaves são os nomes dos arquivos e os valores são as listas de palavras do documento correspondente. As palavras em cada uma das listas devem ser constituídas apenas por letras do alfabeto, estarem lexicamente normalizadas e conterem mais que 1 caracter. Qual o documento cuja lista de palavras resultante possui o **maior** número de palavras repetidas:\n",
    "\n",
    "a) gr22<br>\n",
    "b) ch30<br>\n",
    "c) au2<br>\n",
    "d) au8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsXwords = {}\n",
    "\n",
    "for key, value in docs.items():\n",
    "    words = nltk.word_tokenize(value) #CRIA A LISTA DE PALAVRAS\n",
    "    words = [w.lower() for w in words if w.isalpha() and len(w) != 1] #VERIFICA SE SÃO ALFABÉTICAS E COM MAIS DE 1 CARACTER\n",
    "    words = [PorterStemmer().stem(w) for w in words] # FAZ A NORMALIZAÇÃO LÉXICA DA LISTA\n",
    "    docsXwords[key] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# unificando todas as palavras em uma única lista\n",
    "corpus = [palavras for sublista in list(docsXwords.values()) for palavras in sublista]\n",
    "\n",
    "# removendo repeticoes\n",
    "corpus = list(set(corpus))\n",
    "\n",
    "df_dXp = pd.DataFrame(data=np.zeros((len(list(docs.keys())),len(corpus))),\n",
    "                      index = list(docs.keys()), columns = corpus)\n",
    "\n",
    "for key,value in docsXwords.items():\n",
    "    dtemp = dict(Counter(value))\n",
    "    df_dXp.loc[key,list(dtemp.keys())] = list(dtemp.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "au2    1678.0\ndtype: float64\n"
    }
   ],
   "source": [
    "# for colum in df_dXp.columns():\n",
    "#     print(df_dXp.sum())\n",
    "\n",
    "print(df_dXp.sum(axis=1).sort_values(ascending=False).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA:<br>\n",
    "**LETRA D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3)\n",
    "Utilizando as listas de palavras do dicionário `docsXwords`, quais as três palavras que mais aparecem na coleção de documentos:\n",
    "\n",
    "a) the, is, of<br>\n",
    "b) that, is, of<br>\n",
    "c) the, of, to <br>\n",
    "d) to, is, of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "the    5014.0\nof     2627.0\nto     2611.0\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "df_dXp.sum(axis=0).sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA:<br>\n",
    "**LETRA C**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4)\n",
    "Qual o documento cuja lista de palavras possui o **menor** número de \"stop words\"? Quantas \"stop words\" aparecem neste documento:\n",
    "\n",
    "a) gr5 com 47 \"stop words\"<br>\n",
    "b) gr17 com 47 \"stop words\"<br>\n",
    "c) gr5 com 37 \"stop words\"<br>\n",
    "d) gr17 com 37 \"stop words\"\n",
    "\n",
    "**Dica**: Crie um dicionário onde a chave é o nome do documento e o valor o número de stop words no documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('gr5', 47)\n"
    }
   ],
   "source": [
    "doc_stop = {}\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "for key, value in docsXwords.items():\n",
    "    words = [w for w in value if w in stop_words]\n",
    "    doc_stop[key] = len(words)\n",
    "\n",
    "\n",
    "print(sorted(doc_stop.items(), key=lambda kv: kv[1], reverse=False)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA:<br>\n",
    "**LETRA A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5) \n",
    "Utilize o dicionário `docsXwords` para construir\n",
    "uma matriz Documentos $\\times$ Palavras para a coleção de documentos do diretório `DocCol2`. Utilizando a distância cosseno, qual é o documento mais parecido com o documento 'ch7':\n",
    "\n",
    "a) ch8<br>\n",
    "b) ch16<br>\n",
    "c) ch5<br>\n",
    "d) au8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Documento mais parecido com ch7:  ch16\n"
    }
   ],
   "source": [
    "# encontrando o indice da linha de 'ch7' no DataFrame\n",
    "ch7_id = np.argwhere(df_dXp.index.values=='ch7')[0][0]\n",
    "\n",
    "X = df_dXp.values\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# calculando o cosseno utilizando a formula\n",
    "# cos(x,y) = np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "cosch7 = np.apply_along_axis(lambda x: \n",
    "             np.dot(X[ch7_id],x)/(np.linalg.norm(ch7_id)*np.linalg.norm(x)),1,X)\n",
    "\n",
    "# ordenando e pegando o maior valor (note que o elemento [-1] é o \n",
    "# próprio documento ch7)\n",
    "sim_ch7_id = np.argsort(cosch7)[-2]\n",
    "print('Documento mais parecido com ch7: ',df_dXp.index.values[sim_ch7_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA:<br>\n",
    "**LETRA B**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}